{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a679995615a32bdd09f5213d70b25820aff0f2e5"
   },
   "source": [
    "**INTRODUCTION**\n",
    "\n",
    "Hello! The purpose is to train Prostate Cancer datas with some machine learning and deep learning methods. I'm believe in this course will learn a lot of thing to us. You'll see this kernel:\n",
    "\n",
    "* EDA (Exploratory Data Analysis)\n",
    "* Data Preprocessing (Scaling, Reshaping)\n",
    "* Test-Train Datas Split\n",
    "* Logistic Regression Classification\n",
    "* KNN Classification\n",
    "* Support Vector Machine (SVM) Classification\n",
    "* Naive Bayes Classification\n",
    "* Desicion Tree Classification\n",
    "* Random Forest Classification\n",
    "* Artificial Neural Network\n",
    "* Recurrent Neural Network\n",
    "* Compare all of these Classification Models\n",
    "* Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-10-25T08:41:59.518929Z",
     "iopub.status.busy": "2023-10-25T08:41:59.518273Z",
     "iopub.status.idle": "2023-10-25T08:41:59.566003Z",
     "shell.execute_reply": "2023-10-25T08:41:59.565195Z",
     "shell.execute_reply.started": "2023-10-25T08:41:59.518625Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Prostate_Cancer.csv']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import confusion_matrix # We'll use a lot of times it!\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2023-10-25T08:41:59.567766Z",
     "iopub.status.busy": "2023-10-25T08:41:59.567295Z",
     "iopub.status.idle": "2023-10-25T08:41:59.576322Z",
     "shell.execute_reply": "2023-10-25T08:41:59.575133Z",
     "shell.execute_reply.started": "2023-10-25T08:41:59.567697Z"
    }
   },
   "outputs": [],
   "source": [
    "Cancer = pd.read_csv('../input/Prostate_Cancer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "5e5558aa7e42975c3cb3bb5be8fcdf63d2b8d75e",
    "execution": {
     "iopub.execute_input": "2023-10-25T08:41:59.578186Z",
     "iopub.status.busy": "2023-10-25T08:41:59.577563Z",
     "iopub.status.idle": "2023-10-25T08:41:59.596208Z",
     "shell.execute_reply": "2023-10-25T08:41:59.595175Z",
     "shell.execute_reply.started": "2023-10-25T08:41:59.578092Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 10 columns):\n",
      "id                   100 non-null int64\n",
      "diagnosis_result     100 non-null object\n",
      "radius               100 non-null int64\n",
      "texture              100 non-null int64\n",
      "perimeter            100 non-null int64\n",
      "area                 100 non-null int64\n",
      "smoothness           100 non-null float64\n",
      "compactness          100 non-null float64\n",
      "symmetry             100 non-null float64\n",
      "fractal_dimension    100 non-null float64\n",
      "dtypes: float64(4), int64(5), object(1)\n",
      "memory usage: 7.9+ KB\n"
     ]
    }
   ],
   "source": [
    "Cancer.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "73f8fc7a937835b320251278256f0d26d79706b2",
    "execution": {
     "iopub.execute_input": "2023-10-25T08:41:59.598797Z",
     "iopub.status.busy": "2023-10-25T08:41:59.598306Z",
     "iopub.status.idle": "2023-10-25T08:41:59.638474Z",
     "shell.execute_reply": "2023-10-25T08:41:59.637423Z",
     "shell.execute_reply.started": "2023-10-25T08:41:59.598730Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis_result</th>\n",
       "      <th>radius</th>\n",
       "      <th>texture</th>\n",
       "      <th>perimeter</th>\n",
       "      <th>area</th>\n",
       "      <th>smoothness</th>\n",
       "      <th>compactness</th>\n",
       "      <th>symmetry</th>\n",
       "      <th>fractal_dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>23</td>\n",
       "      <td>12</td>\n",
       "      <td>151</td>\n",
       "      <td>954</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.278</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>133</td>\n",
       "      <td>1326</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>130</td>\n",
       "      <td>1203</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>78</td>\n",
       "      <td>386</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.284</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>M</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>135</td>\n",
       "      <td>1297</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>B</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>83</td>\n",
       "      <td>477</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.209</td>\n",
       "      <td>0.076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>M</td>\n",
       "      <td>16</td>\n",
       "      <td>26</td>\n",
       "      <td>120</td>\n",
       "      <td>1040</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>M</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "      <td>90</td>\n",
       "      <td>578</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>M</td>\n",
       "      <td>19</td>\n",
       "      <td>24</td>\n",
       "      <td>88</td>\n",
       "      <td>520</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>11</td>\n",
       "      <td>84</td>\n",
       "      <td>476</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id diagnosis_result        ...          symmetry  fractal_dimension\n",
       "0   1                M        ...             0.242              0.079\n",
       "1   2                B        ...             0.181              0.057\n",
       "2   3                M        ...             0.207              0.060\n",
       "3   4                M        ...             0.260              0.097\n",
       "4   5                M        ...             0.181              0.059\n",
       "5   6                B        ...             0.209              0.076\n",
       "6   7                M        ...             0.179              0.057\n",
       "7   8                M        ...             0.220              0.075\n",
       "8   9                M        ...             0.235              0.074\n",
       "9  10                M        ...             0.203              0.082\n",
       "\n",
       "[10 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cancer.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "7f605aa194d543d468d79491735e5f66581839fd",
    "execution": {
     "iopub.execute_input": "2023-10-25T08:41:59.639727Z",
     "iopub.status.busy": "2023-10-25T08:41:59.639478Z",
     "iopub.status.idle": "2023-10-25T08:41:59.667023Z",
     "shell.execute_reply": "2023-10-25T08:41:59.666147Z",
     "shell.execute_reply.started": "2023-10-25T08:41:59.639682Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis_result</th>\n",
       "      <th>radius</th>\n",
       "      <th>texture</th>\n",
       "      <th>perimeter</th>\n",
       "      <th>area</th>\n",
       "      <th>smoothness</th>\n",
       "      <th>compactness</th>\n",
       "      <th>symmetry</th>\n",
       "      <th>fractal_dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>M</td>\n",
       "      <td>23</td>\n",
       "      <td>16</td>\n",
       "      <td>132</td>\n",
       "      <td>1264</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>B</td>\n",
       "      <td>22</td>\n",
       "      <td>14</td>\n",
       "      <td>78</td>\n",
       "      <td>451</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>B</td>\n",
       "      <td>19</td>\n",
       "      <td>27</td>\n",
       "      <td>62</td>\n",
       "      <td>295</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>B</td>\n",
       "      <td>21</td>\n",
       "      <td>24</td>\n",
       "      <td>74</td>\n",
       "      <td>413</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>M</td>\n",
       "      <td>16</td>\n",
       "      <td>27</td>\n",
       "      <td>94</td>\n",
       "      <td>643</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id diagnosis_result        ...          symmetry  fractal_dimension\n",
       "95   96                M        ...             0.210              0.056\n",
       "96   97                B        ...             0.190              0.066\n",
       "97   98                B        ...             0.135              0.069\n",
       "98   99                B        ...             0.162              0.066\n",
       "99  100                M        ...             0.188              0.064\n",
       "\n",
       "[5 rows x 10 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cancer.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "0dea2bf6bf39c45d21f4528fb0981c579899a63d",
    "execution": {
     "iopub.execute_input": "2023-10-25T08:41:59.668853Z",
     "iopub.status.busy": "2023-10-25T08:41:59.668585Z",
     "iopub.status.idle": "2023-10-25T08:41:59.724817Z",
     "shell.execute_reply": "2023-10-25T08:41:59.723856Z",
     "shell.execute_reply.started": "2023-10-25T08:41:59.668807Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>radius</th>\n",
       "      <th>texture</th>\n",
       "      <th>perimeter</th>\n",
       "      <th>area</th>\n",
       "      <th>smoothness</th>\n",
       "      <th>compactness</th>\n",
       "      <th>symmetry</th>\n",
       "      <th>fractal_dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>50.500000</td>\n",
       "      <td>16.850000</td>\n",
       "      <td>18.230000</td>\n",
       "      <td>96.780000</td>\n",
       "      <td>702.880000</td>\n",
       "      <td>0.102730</td>\n",
       "      <td>0.126700</td>\n",
       "      <td>0.193170</td>\n",
       "      <td>0.064690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>29.011492</td>\n",
       "      <td>4.879094</td>\n",
       "      <td>5.192954</td>\n",
       "      <td>23.676089</td>\n",
       "      <td>319.710895</td>\n",
       "      <td>0.014642</td>\n",
       "      <td>0.061144</td>\n",
       "      <td>0.030785</td>\n",
       "      <td>0.008151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.038000</td>\n",
       "      <td>0.135000</td>\n",
       "      <td>0.053000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>25.750000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>82.500000</td>\n",
       "      <td>476.750000</td>\n",
       "      <td>0.093500</td>\n",
       "      <td>0.080500</td>\n",
       "      <td>0.172000</td>\n",
       "      <td>0.059000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>50.500000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>17.500000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>644.000000</td>\n",
       "      <td>0.102000</td>\n",
       "      <td>0.118500</td>\n",
       "      <td>0.190000</td>\n",
       "      <td>0.063000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>75.250000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>22.250000</td>\n",
       "      <td>114.250000</td>\n",
       "      <td>917.000000</td>\n",
       "      <td>0.112000</td>\n",
       "      <td>0.157000</td>\n",
       "      <td>0.209000</td>\n",
       "      <td>0.069000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>172.000000</td>\n",
       "      <td>1878.000000</td>\n",
       "      <td>0.143000</td>\n",
       "      <td>0.345000</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>0.097000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id      radius        ...            symmetry  fractal_dimension\n",
       "count  100.000000  100.000000        ...          100.000000         100.000000\n",
       "mean    50.500000   16.850000        ...            0.193170           0.064690\n",
       "std     29.011492    4.879094        ...            0.030785           0.008151\n",
       "min      1.000000    9.000000        ...            0.135000           0.053000\n",
       "25%     25.750000   12.000000        ...            0.172000           0.059000\n",
       "50%     50.500000   17.000000        ...            0.190000           0.063000\n",
       "75%     75.250000   21.000000        ...            0.209000           0.069000\n",
       "max    100.000000   25.000000        ...            0.304000           0.097000\n",
       "\n",
       "[8 rows x 9 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cancer.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "bc63d2953223deb5d2a369185f98f1235f5a4489",
    "execution": {
     "iopub.execute_input": "2023-10-25T08:41:59.726577Z",
     "iopub.status.busy": "2023-10-25T08:41:59.726135Z",
     "iopub.status.idle": "2023-10-25T08:41:59.733361Z",
     "shell.execute_reply": "2023-10-25T08:41:59.732458Z",
     "shell.execute_reply.started": "2023-10-25T08:41:59.726373Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'diagnosis_result', 'radius', 'texture', 'perimeter', 'area',\n",
       "       'smoothness', 'compactness', 'symmetry', 'fractal_dimension'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cancer.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "7f24b49bec7a5c0498d0d1687951532eb2802928",
    "execution": {
     "iopub.execute_input": "2023-10-25T08:41:59.734980Z",
     "iopub.status.busy": "2023-10-25T08:41:59.734594Z",
     "iopub.status.idle": "2023-10-25T08:41:59.744576Z",
     "shell.execute_reply": "2023-10-25T08:41:59.743681Z",
     "shell.execute_reply.started": "2023-10-25T08:41:59.734920Z"
    }
   },
   "outputs": [],
   "source": [
    "# We don't care id of the columns. So, we drop that!\n",
    "Cancer.drop(['id'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "fea789ad3a09ca6599247903c7e15a2f8e32a253",
    "execution": {
     "iopub.execute_input": "2023-10-25T08:41:59.747071Z",
     "iopub.status.busy": "2023-10-25T08:41:59.746170Z",
     "iopub.status.idle": "2023-10-25T08:41:59.780361Z",
     "shell.execute_reply": "2023-10-25T08:41:59.779155Z",
     "shell.execute_reply.started": "2023-10-25T08:41:59.747006Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis_result</th>\n",
       "      <th>radius</th>\n",
       "      <th>texture</th>\n",
       "      <th>perimeter</th>\n",
       "      <th>area</th>\n",
       "      <th>smoothness</th>\n",
       "      <th>compactness</th>\n",
       "      <th>symmetry</th>\n",
       "      <th>fractal_dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>23</td>\n",
       "      <td>12</td>\n",
       "      <td>151</td>\n",
       "      <td>954</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.278</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>133</td>\n",
       "      <td>1326</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>130</td>\n",
       "      <td>1203</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>78</td>\n",
       "      <td>386</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.284</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>135</td>\n",
       "      <td>1297</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  diagnosis_result  radius        ...          symmetry  fractal_dimension\n",
       "0                M      23        ...             0.242              0.079\n",
       "1                B       9        ...             0.181              0.057\n",
       "2                M      21        ...             0.207              0.060\n",
       "3                M      14        ...             0.260              0.097\n",
       "4                M       9        ...             0.181              0.059\n",
       "\n",
       "[5 rows x 9 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cancer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "f05f47ec1176fe84f7651fbd472dc81dc66143a1",
    "execution": {
     "iopub.execute_input": "2023-10-25T08:41:59.782295Z",
     "iopub.status.busy": "2023-10-25T08:41:59.781948Z",
     "iopub.status.idle": "2023-10-25T08:41:59.791880Z",
     "shell.execute_reply": "2023-10-25T08:41:59.791138Z",
     "shell.execute_reply.started": "2023-10-25T08:41:59.782233Z"
    }
   },
   "outputs": [],
   "source": [
    "# diagnosis_result is the most important column for us. Because we'll classify datas depend on this column.\n",
    "# We have to integers for classification. Therefore, we must convert them from object to integer.\n",
    "Cancer.diagnosis_result = [1 if each == 'M' else 0 for each in Cancer.diagnosis_result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "87b9aaf92ea781bb739f752dfc50a509ce1c013b",
    "execution": {
     "iopub.execute_input": "2023-10-25T08:41:59.793281Z",
     "iopub.status.busy": "2023-10-25T08:41:59.792865Z",
     "iopub.status.idle": "2023-10-25T08:41:59.808117Z",
     "shell.execute_reply": "2023-10-25T08:41:59.807224Z",
     "shell.execute_reply.started": "2023-10-25T08:41:59.793233Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    62\n",
       "0    38\n",
       "Name: diagnosis_result, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check it.\n",
    "Cancer.diagnosis_result.value_counts()\n",
    "# And then, we assigned 1 and 0 to M and B. Let's some classification!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "21161b74913379540eba9a143ba7529200e296bb",
    "execution": {
     "iopub.execute_input": "2023-10-25T08:41:59.809723Z",
     "iopub.status.busy": "2023-10-25T08:41:59.809253Z",
     "iopub.status.idle": "2023-10-25T08:41:59.820357Z",
     "shell.execute_reply": "2023-10-25T08:41:59.819587Z",
     "shell.execute_reply.started": "2023-10-25T08:41:59.809667Z"
    }
   },
   "outputs": [],
   "source": [
    "# We should assign x and y values for test-train datas split.\n",
    "y = Cancer.diagnosis_result.values\n",
    "x_data = Cancer.drop(['diagnosis_result'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "3d040dc3e591b2a30996e614f709980719506e9e",
    "execution": {
     "iopub.execute_input": "2023-10-25T08:41:59.823747Z",
     "iopub.status.busy": "2023-10-25T08:41:59.823265Z",
     "iopub.status.idle": "2023-10-25T08:41:59.836175Z",
     "shell.execute_reply": "2023-10-25T08:41:59.834946Z",
     "shell.execute_reply.started": "2023-10-25T08:41:59.823502Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1,\n",
       "       0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See our values\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "17f12e91c50682da8a14a5448517586cfd94f903",
    "execution": {
     "iopub.execute_input": "2023-10-25T08:41:59.837804Z",
     "iopub.status.busy": "2023-10-25T08:41:59.837438Z",
     "iopub.status.idle": "2023-10-25T08:41:59.868100Z",
     "shell.execute_reply": "2023-10-25T08:41:59.866945Z",
     "shell.execute_reply.started": "2023-10-25T08:41:59.837742Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius</th>\n",
       "      <th>texture</th>\n",
       "      <th>perimeter</th>\n",
       "      <th>area</th>\n",
       "      <th>smoothness</th>\n",
       "      <th>compactness</th>\n",
       "      <th>symmetry</th>\n",
       "      <th>fractal_dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>12</td>\n",
       "      <td>151</td>\n",
       "      <td>954</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.278</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>133</td>\n",
       "      <td>1326</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>130</td>\n",
       "      <td>1203</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>78</td>\n",
       "      <td>386</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.284</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>135</td>\n",
       "      <td>1297</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   radius  texture        ...          symmetry  fractal_dimension\n",
       "0      23       12        ...             0.242              0.079\n",
       "1       9       13        ...             0.181              0.057\n",
       "2      21       27        ...             0.207              0.060\n",
       "3      14       16        ...             0.260              0.097\n",
       "4       9       19        ...             0.181              0.059\n",
       "\n",
       "[5 rows x 8 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "732d8ab954f68af7b0d89eec4fa6789dcdd2d8e6",
    "execution": {
     "iopub.execute_input": "2023-10-25T08:41:59.869687Z",
     "iopub.status.busy": "2023-10-25T08:41:59.869402Z",
     "iopub.status.idle": "2023-10-25T08:41:59.883534Z",
     "shell.execute_reply": "2023-10-25T08:41:59.882346Z",
     "shell.execute_reply.started": "2023-10-25T08:41:59.869635Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "# Normalization: Normalization means all of the values of data, scale between 0 and 1.\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "x = scaler.fit_transform(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "76764d713cb7aa2c9bd0310d471b539f455fe4d5",
    "execution": {
     "iopub.execute_input": "2023-10-25T08:41:59.886052Z",
     "iopub.status.busy": "2023-10-25T08:41:59.885439Z",
     "iopub.status.idle": "2023-10-25T08:41:59.907610Z",
     "shell.execute_reply": "2023-10-25T08:41:59.906363Z",
     "shell.execute_reply.started": "2023-10-25T08:41:59.885984Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.875     , 0.0625    , 0.825     , 0.44868735, 1.        ,\n",
       "        0.78175896, 0.63313609, 0.59090909],\n",
       "       [0.        , 0.125     , 0.675     , 0.67064439, 1.        ,\n",
       "        0.13355049, 0.27218935, 0.09090909],\n",
       "       [0.75      , 1.        , 0.65      , 0.59725537, 0.75342466,\n",
       "        0.39739414, 0.4260355 , 0.15909091],\n",
       "       [0.3125    , 0.3125    , 0.21666667, 0.1097852 , 0.        ,\n",
       "        0.80130293, 0.73964497, 1.        ],\n",
       "       [0.        , 0.5       , 0.69166667, 0.65334129, 0.97260274,\n",
       "        0.30944625, 0.27218935, 0.13636364],\n",
       "       [1.        , 0.875     , 0.25833333, 0.16408115, 0.79452055,\n",
       "        0.42996743, 0.43786982, 0.52272727],\n",
       "       [0.4375    , 0.9375    , 0.56666667, 0.5       , 0.34246575,\n",
       "        0.23127036, 0.26035503, 0.09090909],\n",
       "       [0.375     , 0.4375    , 0.31666667, 0.22434368, 0.67123288,\n",
       "        0.41368078, 0.50295858, 0.5       ],\n",
       "       [0.625     , 0.8125    , 0.3       , 0.18973747, 0.78082192,\n",
       "        0.50488599, 0.59171598, 0.47727273],\n",
       "       [1.        , 0.        , 0.26666667, 0.16348449, 0.67123288,\n",
       "        0.65798046, 0.40236686, 0.65909091],\n",
       "       [0.9375    , 0.625     , 0.425     , 0.35560859, 0.16438356,\n",
       "        0.09446254, 0.10650888, 0.09090909],\n",
       "       [0.5       , 0.25      , 0.43333333, 0.34546539, 0.36986301,\n",
       "        0.29641694, 0.28994083, 0.18181818],\n",
       "       [0.3125    , 0.25      , 0.66666667, 0.54952267, 0.36986301,\n",
       "        0.67752443, 0.62130178, 0.56818182],\n",
       "       [0.1875    , 0.6875    , 0.43333333, 0.34665871, 0.19178082,\n",
       "        0.2019544 , 0.29585799, 0.        ],\n",
       "       [0.1875    , 0.125     , 0.35      , 0.22434368, 0.5890411 ,\n",
       "        0.62214984, 0.4260355 , 0.54545455],\n",
       "       [0.8125    , 0.5       , 0.375     , 0.27267303, 0.60273973,\n",
       "        0.39739414, 0.56213018, 0.40909091],\n",
       "       [0.0625    , 0.3125    , 0.35833333, 0.28818616, 0.39726027,\n",
       "        0.11074919, 0.14201183, 0.13636364],\n",
       "       [0.375     , 0.1875    , 0.46666667, 0.35620525, 0.64383562,\n",
       "        0.53420195, 0.47928994, 0.47727273],\n",
       "       [0.6875    , 0.1875    , 0.65      , 0.63126492, 0.38356164,\n",
       "        0.21172638, 0.13609467, 0.02272727],\n",
       "       [0.5       , 0.        , 0.29166667, 0.21718377, 0.38356164,\n",
       "        0.14006515, 0.31952663, 0.11363636],\n",
       "       [0.4375    , 0.1875    , 0.28333333, 0.18973747, 0.52054795,\n",
       "        0.28990228, 0.36686391, 0.34090909],\n",
       "       [0.5       , 0.8125    , 0.06666667, 0.04295943, 0.43835616,\n",
       "        0.08794788, 0.27810651, 0.36363636],\n",
       "       [0.6875    , 1.        , 0.425     , 0.29952267, 0.50684932,\n",
       "        0.5732899 , 0.69230769, 0.38636364],\n",
       "       [0.625     , 0.0625    , 0.70833333, 0.71718377, 0.32876712,\n",
       "        0.20846906, 0.24852071, 0.        ],\n",
       "       [0.        , 0.125     , 0.48333333, 0.41945107, 0.57534247,\n",
       "        0.35179153, 0.38461538, 0.22727273],\n",
       "       [0.625     , 1.        , 0.53333333, 0.42422434, 0.67123288,\n",
       "        0.61889251, 1.        , 0.47727273],\n",
       "       [0.0625    , 0.8125    , 0.375     , 0.26431981, 0.47945205,\n",
       "        0.48534202, 0.53254438, 0.36363636],\n",
       "       [0.4375    , 0.8125    , 0.58333333, 0.53221957, 0.32876712,\n",
       "        0.2247557 , 0.20710059, 0.09090909],\n",
       "       [0.375     , 0.25      , 0.41666667, 0.31622912, 0.52054795,\n",
       "        0.42996743, 0.34319527, 0.27272727],\n",
       "       [0.125     , 0.3125    , 0.525     , 0.44928401, 0.38356164,\n",
       "        0.25407166, 0.23076923, 0.18181818],\n",
       "       [0.125     , 0.6875    , 0.60833333, 0.52863962, 0.49315068,\n",
       "        0.49185668, 0.49112426, 0.20454545],\n",
       "       [0.875     , 0.9375    , 0.21666667, 0.14260143, 0.56164384,\n",
       "        0.3713355 , 0.56213018, 0.56818182],\n",
       "       [0.6875    , 0.4375    , 0.50833333, 0.41587112, 0.68493151,\n",
       "        0.36482085, 0.53254438, 0.25      ],\n",
       "       [0.125     , 0.625     , 0.63333333, 0.57279236, 0.32876712,\n",
       "        0.43648208, 0.29585799, 0.22727273],\n",
       "       [0.4375    , 0.75      , 0.45833333, 0.36097852, 0.46575342,\n",
       "        0.38436482, 0.38461538, 0.27272727],\n",
       "       [0.0625    , 0.125     , 0.48333333, 0.39856802, 0.35616438,\n",
       "        0.31270358, 0.32544379, 0.09090909],\n",
       "       [0.5625    , 0.0625    , 0.35      , 0.2571599 , 0.38356164,\n",
       "        0.23452769, 0.31952663, 0.18181818],\n",
       "       [0.75      , 0.        , 0.25833333, 0.19212411, 0.2739726 ,\n",
       "        0.        , 0.07100592, 0.13636364],\n",
       "       [0.125     , 0.25      , 0.36666667, 0.29653938, 0.32876712,\n",
       "        0.04234528, 0.13017751, 0.04545455],\n",
       "       [0.0625    , 0.1875    , 0.3       , 0.21300716, 0.43835616,\n",
       "        0.28664495, 0.21893491, 0.25      ],\n",
       "       [0.9375    , 0.3125    , 0.28333333, 0.21539379, 0.16438356,\n",
       "        0.07166124, 0.25443787, 0.06818182],\n",
       "       [0.625     , 1.        , 0.16666667, 0.10083532, 0.7260274 ,\n",
       "        0.27361564, 0.32544379, 0.36363636],\n",
       "       [0.125     , 0.        , 0.63333333, 0.53818616, 0.28767123,\n",
       "        0.58957655, 0.56804734, 0.22727273],\n",
       "       [0.375     , 0.625     , 0.29166667, 0.20465394, 0.46575342,\n",
       "        0.34527687, 0.36686391, 0.34090909],\n",
       "       [0.0625    , 0.25      , 0.275     , 0.19689737, 0.36986301,\n",
       "        0.21824104, 0.23668639, 0.20454545],\n",
       "       [0.5625    , 0.        , 0.6       , 0.52147971, 0.54794521,\n",
       "        0.4267101 , 0.33136095, 0.15909091],\n",
       "       [0.8125    , 0.0625    , 0.        , 0.        , 0.21917808,\n",
       "        0.06840391, 0.24852071, 0.27272727],\n",
       "       [0.6875    , 0.1875    , 0.28333333, 0.19868735, 0.63013699,\n",
       "        0.27687296, 0.46153846, 0.34090909],\n",
       "       [0.6875    , 0.625     , 0.21666667, 0.1473747 , 0.45205479,\n",
       "        0.17263844, 0.19526627, 0.15909091],\n",
       "       [1.        , 0.        , 0.29166667, 0.21420048, 0.24657534,\n",
       "        0.12703583, 0.27218935, 0.09090909],\n",
       "       [0.625     , 0.875     , 0.19166667, 0.13484487, 0.21917808,\n",
       "        0.03908795, 0.0887574 , 0.13636364],\n",
       "       [0.625     , 0.6875    , 0.29166667, 0.22076372, 0.09589041,\n",
       "        0.07491857, 0.        , 0.15909091],\n",
       "       [1.        , 0.25      , 0.2       , 0.14081146, 0.17808219,\n",
       "        0.03257329, 0.30769231, 0.18181818],\n",
       "       [0.3125    , 0.9375    , 0.56666667, 0.49582339, 0.61643836,\n",
       "        0.36156352, 0.43786982, 0.22727273],\n",
       "       [0.5625    , 0.875     , 0.375     , 0.3048926 , 0.28767123,\n",
       "        0.10749186, 0.15976331, 0.09090909],\n",
       "       [0.5625    , 0.125     , 0.175     , 0.12350835, 0.34246575,\n",
       "        0.05537459, 0.33727811, 0.13636364],\n",
       "       [0.0625    , 0.5       , 0.61666667, 0.56682578, 0.47945205,\n",
       "        0.28990228, 0.33727811, 0.15909091],\n",
       "       [0.5       , 0.5625    , 0.36666667, 0.27147971, 0.60273973,\n",
       "        0.32247557, 0.40236686, 0.34090909],\n",
       "       [0.8125    , 0.25      , 0.25833333, 0.19391408, 0.15068493,\n",
       "        0.        , 0.27810651, 0.04545455],\n",
       "       [0.875     , 0.9375    , 0.01666667, 0.01372315, 0.38356164,\n",
       "        0.04885993, 0.19526627, 0.43181818],\n",
       "       [0.375     , 0.4375    , 0.10833333, 0.06563246, 0.5890411 ,\n",
       "        0.14006515, 0.82248521, 0.38636364],\n",
       "       [1.        , 0.25      , 0.025     , 0.01193317, 0.73972603,\n",
       "        0.16938111, 0.28402367, 0.34090909],\n",
       "       [0.1875    , 0.6875    , 0.36666667, 0.26491647, 0.47945205,\n",
       "        0.53094463, 0.35502959, 0.45454545],\n",
       "       [0.9375    , 0.375     , 0.05833333, 0.03520286, 0.09589041,\n",
       "        0.16286645, 0.58579882, 0.38636364],\n",
       "       [0.4375    , 0.5       , 0.25833333, 0.17720764, 0.57534247,\n",
       "        0.28664495, 0.33136095, 0.29545455],\n",
       "       [0.125     , 0.625     , 0.375     , 0.27804296, 0.64383562,\n",
       "        0.35830619, 0.35502959, 0.31818182],\n",
       "       [0.1875    , 0.125     , 0.06666667, 0.03997613, 0.46575342,\n",
       "        0.13029316, 0.21893491, 0.36363636],\n",
       "       [0.5625    , 0.0625    , 0.16666667, 0.11455847, 0.15068493,\n",
       "        0.02931596, 0.10059172, 0.09090909],\n",
       "       [0.4375    , 0.375     , 0.05833333, 0.02923628, 0.50684932,\n",
       "        0.33550489, 0.44970414, 0.61363636],\n",
       "       [0.5       , 0.625     , 0.24166667, 0.17959427, 0.38356164,\n",
       "        0.04560261, 0.14201183, 0.09090909],\n",
       "       [0.75      , 0.4375    , 0.6       , 0.55369928, 0.2739726 ,\n",
       "        0.21172638, 0.13609467, 0.04545455],\n",
       "       [0.        , 0.9375    , 0.05833333, 0.02505967, 0.38356164,\n",
       "        0.37459283, 0.32544379, 0.84090909],\n",
       "       [0.75      , 0.0625    , 0.51666667, 0.43377088, 0.50684932,\n",
       "        0.4723127 , 0.34319527, 0.27272727],\n",
       "       [0.8125    , 0.875     , 0.31666667, 0.22792363, 0.42465753,\n",
       "        0.29315961, 0.18343195, 0.29545455],\n",
       "       [0.5625    , 0.125     , 0.225     , 0.16050119, 0.30136986,\n",
       "        0.09771987, 0.21893491, 0.13636364],\n",
       "       [0.75      , 0.4375    , 0.43333333, 0.36754177, 0.30136986,\n",
       "        0.14983713, 0.26627219, 0.02272727],\n",
       "       [0.0625    , 0.375     , 0.3       , 0.21300716, 0.80821918,\n",
       "        0.21824104, 0.62130178, 0.29545455],\n",
       "       [0.125     , 0.625     , 0.56666667, 0.4797136 , 0.50684932,\n",
       "        0.57654723, 0.47337278, 0.31818182],\n",
       "       [0.4375    , 0.4375    , 0.76666667, 0.62231504, 0.80821918,\n",
       "        1.        , 0.92307692, 0.63636364],\n",
       "       [0.8125    , 0.3125    , 0.25833333, 0.18138425, 0.39726027,\n",
       "        0.18566775, 0.21893491, 0.15909091],\n",
       "       [0.0625    , 0.4375    , 0.18333333, 0.11933174, 0.54794521,\n",
       "        0.18241042, 0.28994083, 0.38636364],\n",
       "       [0.5       , 0.625     , 0.28333333, 0.18973747, 0.52054795,\n",
       "        0.37785016, 0.34911243, 0.36363636],\n",
       "       [0.0625    , 0.25      , 1.        , 1.        , 0.49315068,\n",
       "        0.74592834, 0.28402367, 0.34090909],\n",
       "       [0.6875    , 0.1875    , 0.64166667, 0.5548926 , 0.71232877,\n",
       "        0.45928339, 0.16568047, 0.43181818],\n",
       "       [1.        , 0.625     , 0.20833333, 0.14379475, 0.36986301,\n",
       "        0.11074919, 0.43195266, 0.15909091],\n",
       "       [0.3125    , 0.125     , 0.575     , 0.52088305, 0.39726027,\n",
       "        0.21824104, 0.46153846, 0.15909091],\n",
       "       [0.625     , 0.9375    , 0.35      , 0.26610979, 0.32876712,\n",
       "        0.19869707, 0.43195266, 0.06818182],\n",
       "       [0.625     , 0.        , 0.58333333, 0.52147971, 0.2739726 ,\n",
       "        0.27035831, 0.35502959, 0.06818182],\n",
       "       [0.125     , 0.        , 0.23333333, 0.1575179 , 0.24657534,\n",
       "        0.18241042, 0.34319527, 0.25      ],\n",
       "       [0.1875    , 0.75      , 0.36666667, 0.26849642, 0.5890411 ,\n",
       "        0.31270358, 0.4556213 , 0.22727273],\n",
       "       [0.875     , 1.        , 0.35833333, 0.27505967, 0.2739726 ,\n",
       "        0.15635179, 0.20118343, 0.13636364],\n",
       "       [0.0625    , 0.0625    , 0.4       , 0.31384248, 0.30136986,\n",
       "        0.21498371, 0.21893491, 0.18181818],\n",
       "       [0.3125    , 0.1875    , 0.275     , 0.20883055, 0.05479452,\n",
       "        0.04234528, 0.02366864, 0.        ],\n",
       "       [0.0625    , 0.375     , 0.29166667, 0.21062053, 0.43835616,\n",
       "        0.14332248, 0.17159763, 0.09090909],\n",
       "       [0.8125    , 0.9375    , 0.4       , 0.30071599, 0.46575342,\n",
       "        0.38110749, 0.30177515, 0.22727273],\n",
       "       [0.875     , 0.3125    , 0.66666667, 0.63365155, 0.28767123,\n",
       "        0.3029316 , 0.44378698, 0.06818182],\n",
       "       [0.8125    , 0.1875    , 0.21666667, 0.14856802, 0.47945205,\n",
       "        0.10749186, 0.32544379, 0.29545455],\n",
       "       [0.625     , 1.        , 0.08333333, 0.05548926, 0.43835616,\n",
       "        0.04885993, 0.        , 0.36363636],\n",
       "       [0.75      , 0.8125    , 0.18333333, 0.12589499, 0.2739726 ,\n",
       "        0.12052117, 0.15976331, 0.29545455],\n",
       "       [0.4375    , 1.        , 0.35      , 0.26312649, 0.38356164,\n",
       "        0.247557  , 0.31360947, 0.25      ]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "63a63a87d3ce57ae5eba95acacca1b5be355b7f2",
    "execution": {
     "iopub.execute_input": "2023-10-25T08:41:59.910866Z",
     "iopub.status.busy": "2023-10-25T08:41:59.910303Z",
     "iopub.status.idle": "2023-10-25T08:41:59.918421Z",
     "shell.execute_reply": "2023-10-25T08:41:59.917401Z",
     "shell.execute_reply.started": "2023-10-25T08:41:59.910575Z"
    }
   },
   "outputs": [],
   "source": [
    "# We are ready to split datas as train and test.\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2,random_state=42)\n",
    "#%40 data will assign as 'Test Datas'\n",
    "method_names=[] # In Conclusion part, I'll try to show you which method gave the best result.\n",
    "method_scores=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "753ff7cdc84f6d495b67a5539f04ea8937e5d780",
    "execution": {
     "iopub.execute_input": "2023-10-25T08:41:59.920040Z",
     "iopub.status.busy": "2023-10-25T08:41:59.919617Z",
     "iopub.status.idle": "2023-10-25T08:41:59.945777Z",
     "shell.execute_reply": "2023-10-25T08:41:59.944359Z",
     "shell.execute_reply.started": "2023-10-25T08:41:59.919984Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5625    , 0.125     , 0.175     , 0.12350835, 0.34246575,\n",
       "        0.05537459, 0.33727811, 0.13636364],\n",
       "       [0.125     , 0.        , 0.23333333, 0.1575179 , 0.24657534,\n",
       "        0.18241042, 0.34319527, 0.25      ],\n",
       "       [0.0625    , 0.8125    , 0.375     , 0.26431981, 0.47945205,\n",
       "        0.48534202, 0.53254438, 0.36363636],\n",
       "       [0.125     , 0.        , 0.63333333, 0.53818616, 0.28767123,\n",
       "        0.58957655, 0.56804734, 0.22727273],\n",
       "       [0.5       , 0.625     , 0.24166667, 0.17959427, 0.38356164,\n",
       "        0.04560261, 0.14201183, 0.09090909],\n",
       "       [0.8125    , 0.5       , 0.375     , 0.27267303, 0.60273973,\n",
       "        0.39739414, 0.56213018, 0.40909091],\n",
       "       [0.9375    , 0.3125    , 0.28333333, 0.21539379, 0.16438356,\n",
       "        0.07166124, 0.25443787, 0.06818182],\n",
       "       [0.8125    , 0.1875    , 0.21666667, 0.14856802, 0.47945205,\n",
       "        0.10749186, 0.32544379, 0.29545455],\n",
       "       [1.        , 0.        , 0.26666667, 0.16348449, 0.67123288,\n",
       "        0.65798046, 0.40236686, 0.65909091],\n",
       "       [0.75      , 0.0625    , 0.51666667, 0.43377088, 0.50684932,\n",
       "        0.4723127 , 0.34319527, 0.27272727],\n",
       "       [0.5       , 0.25      , 0.43333333, 0.34546539, 0.36986301,\n",
       "        0.29641694, 0.28994083, 0.18181818],\n",
       "       [0.6875    , 0.1875    , 0.28333333, 0.19868735, 0.63013699,\n",
       "        0.27687296, 0.46153846, 0.34090909],\n",
       "       [0.3125    , 0.125     , 0.575     , 0.52088305, 0.39726027,\n",
       "        0.21824104, 0.46153846, 0.15909091],\n",
       "       [0.375     , 0.25      , 0.41666667, 0.31622912, 0.52054795,\n",
       "        0.42996743, 0.34319527, 0.27272727],\n",
       "       [0.0625    , 0.375     , 0.29166667, 0.21062053, 0.43835616,\n",
       "        0.14332248, 0.17159763, 0.09090909],\n",
       "       [1.        , 0.875     , 0.25833333, 0.16408115, 0.79452055,\n",
       "        0.42996743, 0.43786982, 0.52272727],\n",
       "       [0.1875    , 0.125     , 0.06666667, 0.03997613, 0.46575342,\n",
       "        0.13029316, 0.21893491, 0.36363636],\n",
       "       [0.125     , 0.625     , 0.375     , 0.27804296, 0.64383562,\n",
       "        0.35830619, 0.35502959, 0.31818182],\n",
       "       [0.0625    , 0.125     , 0.48333333, 0.39856802, 0.35616438,\n",
       "        0.31270358, 0.32544379, 0.09090909],\n",
       "       [0.0625    , 0.3125    , 0.35833333, 0.28818616, 0.39726027,\n",
       "        0.11074919, 0.14201183, 0.13636364],\n",
       "       [1.        , 0.        , 0.29166667, 0.21420048, 0.24657534,\n",
       "        0.12703583, 0.27218935, 0.09090909],\n",
       "       [0.4375    , 0.75      , 0.45833333, 0.36097852, 0.46575342,\n",
       "        0.38436482, 0.38461538, 0.27272727],\n",
       "       [0.375     , 0.4375    , 0.31666667, 0.22434368, 0.67123288,\n",
       "        0.41368078, 0.50295858, 0.5       ],\n",
       "       [0.875     , 0.3125    , 0.66666667, 0.63365155, 0.28767123,\n",
       "        0.3029316 , 0.44378698, 0.06818182],\n",
       "       [0.4375    , 0.8125    , 0.58333333, 0.53221957, 0.32876712,\n",
       "        0.2247557 , 0.20710059, 0.09090909],\n",
       "       [0.5       , 0.        , 0.29166667, 0.21718377, 0.38356164,\n",
       "        0.14006515, 0.31952663, 0.11363636],\n",
       "       [0.5       , 0.625     , 0.28333333, 0.18973747, 0.52054795,\n",
       "        0.37785016, 0.34911243, 0.36363636],\n",
       "       [0.625     , 1.        , 0.53333333, 0.42422434, 0.67123288,\n",
       "        0.61889251, 1.        , 0.47727273],\n",
       "       [0.1875    , 0.6875    , 0.36666667, 0.26491647, 0.47945205,\n",
       "        0.53094463, 0.35502959, 0.45454545],\n",
       "       [0.1875    , 0.6875    , 0.43333333, 0.34665871, 0.19178082,\n",
       "        0.2019544 , 0.29585799, 0.        ],\n",
       "       [0.        , 0.125     , 0.48333333, 0.41945107, 0.57534247,\n",
       "        0.35179153, 0.38461538, 0.22727273],\n",
       "       [0.3125    , 0.3125    , 0.21666667, 0.1097852 , 0.        ,\n",
       "        0.80130293, 0.73964497, 1.        ],\n",
       "       [0.375     , 0.1875    , 0.46666667, 0.35620525, 0.64383562,\n",
       "        0.53420195, 0.47928994, 0.47727273],\n",
       "       [0.125     , 0.25      , 0.36666667, 0.29653938, 0.32876712,\n",
       "        0.04234528, 0.13017751, 0.04545455],\n",
       "       [0.625     , 0.8125    , 0.3       , 0.18973747, 0.78082192,\n",
       "        0.50488599, 0.59171598, 0.47727273],\n",
       "       [0.4375    , 0.4375    , 0.76666667, 0.62231504, 0.80821918,\n",
       "        1.        , 0.92307692, 0.63636364],\n",
       "       [0.4375    , 0.9375    , 0.56666667, 0.5       , 0.34246575,\n",
       "        0.23127036, 0.26035503, 0.09090909],\n",
       "       [0.4375    , 0.5       , 0.25833333, 0.17720764, 0.57534247,\n",
       "        0.28664495, 0.33136095, 0.29545455],\n",
       "       [0.5625    , 0.0625    , 0.35      , 0.2571599 , 0.38356164,\n",
       "        0.23452769, 0.31952663, 0.18181818],\n",
       "       [0.1875    , 0.75      , 0.36666667, 0.26849642, 0.5890411 ,\n",
       "        0.31270358, 0.4556213 , 0.22727273],\n",
       "       [0.0625    , 0.5       , 0.61666667, 0.56682578, 0.47945205,\n",
       "        0.28990228, 0.33727811, 0.15909091],\n",
       "       [0.4375    , 1.        , 0.35      , 0.26312649, 0.38356164,\n",
       "        0.247557  , 0.31360947, 0.25      ],\n",
       "       [0.5625    , 0.875     , 0.375     , 0.3048926 , 0.28767123,\n",
       "        0.10749186, 0.15976331, 0.09090909],\n",
       "       [0.375     , 0.625     , 0.29166667, 0.20465394, 0.46575342,\n",
       "        0.34527687, 0.36686391, 0.34090909],\n",
       "       [0.625     , 0.875     , 0.19166667, 0.13484487, 0.21917808,\n",
       "        0.03908795, 0.0887574 , 0.13636364],\n",
       "       [0.5625    , 0.0625    , 0.16666667, 0.11455847, 0.15068493,\n",
       "        0.02931596, 0.10059172, 0.09090909],\n",
       "       [0.8125    , 0.0625    , 0.        , 0.        , 0.21917808,\n",
       "        0.06840391, 0.24852071, 0.27272727],\n",
       "       [0.4375    , 0.375     , 0.05833333, 0.02923628, 0.50684932,\n",
       "        0.33550489, 0.44970414, 0.61363636],\n",
       "       [1.        , 0.25      , 0.025     , 0.01193317, 0.73972603,\n",
       "        0.16938111, 0.28402367, 0.34090909],\n",
       "       [0.625     , 1.        , 0.08333333, 0.05548926, 0.43835616,\n",
       "        0.04885993, 0.        , 0.36363636],\n",
       "       [0.8125    , 0.3125    , 0.25833333, 0.18138425, 0.39726027,\n",
       "        0.18566775, 0.21893491, 0.15909091],\n",
       "       [0.625     , 1.        , 0.16666667, 0.10083532, 0.7260274 ,\n",
       "        0.27361564, 0.32544379, 0.36363636],\n",
       "       [0.8125    , 0.25      , 0.25833333, 0.19391408, 0.15068493,\n",
       "        0.        , 0.27810651, 0.04545455],\n",
       "       [0.6875    , 0.625     , 0.21666667, 0.1473747 , 0.45205479,\n",
       "        0.17263844, 0.19526627, 0.15909091],\n",
       "       [0.75      , 0.8125    , 0.18333333, 0.12589499, 0.2739726 ,\n",
       "        0.12052117, 0.15976331, 0.29545455],\n",
       "       [0.5       , 0.5625    , 0.36666667, 0.27147971, 0.60273973,\n",
       "        0.32247557, 0.40236686, 0.34090909],\n",
       "       [0.75      , 0.4375    , 0.43333333, 0.36754177, 0.30136986,\n",
       "        0.14983713, 0.26627219, 0.02272727],\n",
       "       [0.6875    , 0.4375    , 0.50833333, 0.41587112, 0.68493151,\n",
       "        0.36482085, 0.53254438, 0.25      ],\n",
       "       [0.8125    , 0.9375    , 0.4       , 0.30071599, 0.46575342,\n",
       "        0.38110749, 0.30177515, 0.22727273],\n",
       "       [0.875     , 0.9375    , 0.01666667, 0.01372315, 0.38356164,\n",
       "        0.04885993, 0.19526627, 0.43181818],\n",
       "       [0.9375    , 0.375     , 0.05833333, 0.03520286, 0.09589041,\n",
       "        0.16286645, 0.58579882, 0.38636364],\n",
       "       [1.        , 0.625     , 0.20833333, 0.14379475, 0.36986301,\n",
       "        0.11074919, 0.43195266, 0.15909091],\n",
       "       [0.75      , 0.        , 0.25833333, 0.19212411, 0.2739726 ,\n",
       "        0.        , 0.07100592, 0.13636364],\n",
       "       [0.125     , 0.3125    , 0.525     , 0.44928401, 0.38356164,\n",
       "        0.25407166, 0.23076923, 0.18181818],\n",
       "       [0.        , 0.125     , 0.675     , 0.67064439, 1.        ,\n",
       "        0.13355049, 0.27218935, 0.09090909],\n",
       "       [1.        , 0.25      , 0.2       , 0.14081146, 0.17808219,\n",
       "        0.03257329, 0.30769231, 0.18181818],\n",
       "       [0.5       , 0.8125    , 0.06666667, 0.04295943, 0.43835616,\n",
       "        0.08794788, 0.27810651, 0.36363636],\n",
       "       [0.75      , 1.        , 0.65      , 0.59725537, 0.75342466,\n",
       "        0.39739414, 0.4260355 , 0.15909091],\n",
       "       [0.625     , 0.0625    , 0.70833333, 0.71718377, 0.32876712,\n",
       "        0.20846906, 0.24852071, 0.        ],\n",
       "       [0.625     , 0.        , 0.58333333, 0.52147971, 0.2739726 ,\n",
       "        0.27035831, 0.35502959, 0.06818182],\n",
       "       [0.0625    , 0.0625    , 0.4       , 0.31384248, 0.30136986,\n",
       "        0.21498371, 0.21893491, 0.18181818],\n",
       "       [0.5625    , 0.125     , 0.225     , 0.16050119, 0.30136986,\n",
       "        0.09771987, 0.21893491, 0.13636364],\n",
       "       [0.625     , 0.9375    , 0.35      , 0.26610979, 0.32876712,\n",
       "        0.19869707, 0.43195266, 0.06818182],\n",
       "       [0.0625    , 0.25      , 1.        , 1.        , 0.49315068,\n",
       "        0.74592834, 0.28402367, 0.34090909],\n",
       "       [0.4375    , 0.1875    , 0.28333333, 0.18973747, 0.52054795,\n",
       "        0.28990228, 0.36686391, 0.34090909],\n",
       "       [0.375     , 0.4375    , 0.10833333, 0.06563246, 0.5890411 ,\n",
       "        0.14006515, 0.82248521, 0.38636364],\n",
       "       [0.        , 0.9375    , 0.05833333, 0.02505967, 0.38356164,\n",
       "        0.37459283, 0.32544379, 0.84090909],\n",
       "       [0.1875    , 0.125     , 0.35      , 0.22434368, 0.5890411 ,\n",
       "        0.62214984, 0.4260355 , 0.54545455],\n",
       "       [0.3125    , 0.1875    , 0.275     , 0.20883055, 0.05479452,\n",
       "        0.04234528, 0.02366864, 0.        ],\n",
       "       [0.625     , 0.6875    , 0.29166667, 0.22076372, 0.09589041,\n",
       "        0.07491857, 0.        , 0.15909091]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's look at new values.\n",
    "x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2c4637886423e06e40c77bc00a5b88f027572c1f"
   },
   "source": [
    "**And now time to classification!**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "949e0fbc546a778ac9fb85ad065457009d38e27c",
    "execution": {
     "iopub.execute_input": "2023-10-25T08:41:59.947660Z",
     "iopub.status.busy": "2023-10-25T08:41:59.947103Z",
     "iopub.status.idle": "2023-10-25T08:42:00.160451Z",
     "shell.execute_reply": "2023-10-25T08:42:00.159705Z",
     "shell.execute_reply.started": "2023-10-25T08:41:59.947590Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classification Test Accuracy 0.75\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Firstly, we start with Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(x_train, y_train) #Fitting\n",
    "print(\"Logistic Regression Classification Test Accuracy {}\".format(log_reg.score(x_test,y_test)))\n",
    "method_names.append(\"Logistic Reg.\")\n",
    "method_scores.append(log_reg.score(x_test,y_test))\n",
    "\n",
    "#Confusion Matrix\n",
    "y_pred = log_reg.predict(x_test)\n",
    "conf_mat = confusion_matrix(y_test,y_pred)\n",
    "#Visualization Confusion Matrix\n",
    "f, ax = plt.subplots(figsize=(5,5))\n",
    "sns.heatmap(conf_mat,annot=True,linewidths=0.5,linecolor=\"red\",fmt=\".0f\",ax=ax)\n",
    "plt.xlabel(\"Predicted Values\")\n",
    "plt.ylabel(\"True Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "6eb8470d8b5b7e5c44dcc63cd786c326f5be83fc",
    "execution": {
     "iopub.execute_input": "2023-10-25T08:42:00.162464Z",
     "iopub.status.busy": "2023-10-25T08:42:00.161879Z",
     "iopub.status.idle": "2023-10-25T08:42:00.321859Z",
     "shell.execute_reply": "2023-10-25T08:42:00.321001Z",
     "shell.execute_reply.started": "2023-10-25T08:42:00.162400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for Number of Neighbors = 5: 0.8\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Continue with; KNN Classification!\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)  # 5 is optional.\n",
    "knn.fit(x_train,y_train)\n",
    "print(\"Score for Number of Neighbors = 5: {}\".format(knn.score(x_test,y_test)))\n",
    "method_names.append(\"KNN\")\n",
    "method_scores.append(knn.score(x_test,y_test))\n",
    "\n",
    "#Confusion Matrix\n",
    "y_pred = knn.predict(x_test)\n",
    "conf_mat = confusion_matrix(y_test,y_pred)\n",
    "#Visualization Confusion Matrix\n",
    "f, ax = plt.subplots(figsize=(5,5))\n",
    "sns.heatmap(conf_mat,annot=True,linewidths=0.5,linecolor=\"red\",fmt=\".0f\",ax=ax)\n",
    "plt.xlabel(\"Predicted Values\")\n",
    "plt.ylabel(\"True Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "ea5a44d0281f4f34a77c066f0ed12bac885d35cf",
    "execution": {
     "iopub.execute_input": "2023-10-25T08:42:00.323946Z",
     "iopub.status.busy": "2023-10-25T08:42:00.323238Z",
     "iopub.status.idle": "2023-10-25T08:42:00.494504Z",
     "shell.execute_reply": "2023-10-25T08:42:00.493511Z",
     "shell.execute_reply.started": "2023-10-25T08:42:00.323876Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classification Score is: 0.75\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# SVM!\n",
    "from sklearn.svm import SVC\n",
    "svm = SVC(random_state=42)\n",
    "svm.fit(x_train,y_train)\n",
    "print(\"SVM Classification Score is: {}\".format(svm.score(x_test,y_test)))\n",
    "method_names.append(\"SVM\")\n",
    "method_scores.append(svm.score(x_test,y_test))\n",
    "\n",
    "#Confusion Matrix\n",
    "y_pred = svm.predict(x_test)\n",
    "conf_mat = confusion_matrix(y_test,y_pred)\n",
    "#Visualization Confusion Matrix\n",
    "f, ax = plt.subplots(figsize=(5,5))\n",
    "sns.heatmap(conf_mat,annot=True,linewidths=0.5,linecolor=\"red\",fmt=\".0f\",ax=ax)\n",
    "plt.xlabel(\"Predicted Values\")\n",
    "plt.ylabel(\"True Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "19b6321c1b5a18a045dc4e1636e2b368c082769d",
    "execution": {
     "iopub.execute_input": "2023-10-25T08:42:00.496711Z",
     "iopub.status.busy": "2023-10-25T08:42:00.496069Z",
     "iopub.status.idle": "2023-10-25T08:42:00.659266Z",
     "shell.execute_reply": "2023-10-25T08:42:00.658502Z",
     "shell.execute_reply.started": "2023-10-25T08:42:00.496647Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Classification Score: 0.8\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "naive_bayes = GaussianNB()\n",
    "naive_bayes.fit(x_test,y_test)\n",
    "print(\"Naive Bayes Classification Score: {}\".format(naive_bayes.score(x_test,y_test)))\n",
    "method_names.append(\"Naive Bayes\")\n",
    "method_scores.append(naive_bayes.score(x_test,y_test))\n",
    "\n",
    "#Confusion Matrix\n",
    "y_pred = naive_bayes.predict(x_test)\n",
    "conf_mat = confusion_matrix(y_test,y_pred)\n",
    "#Visualization Confusion Matrix\n",
    "f, ax = plt.subplots(figsize=(5,5))\n",
    "sns.heatmap(conf_mat,annot=True,linewidths=0.5,linecolor=\"red\",fmt=\".0f\",ax=ax)\n",
    "plt.xlabel(\"Predicted Values\")\n",
    "plt.ylabel(\"True Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "51faaac7300e99421c31e7fd635ee977392caa73",
    "execution": {
     "iopub.execute_input": "2023-10-25T08:42:00.661403Z",
     "iopub.status.busy": "2023-10-25T08:42:00.660782Z",
     "iopub.status.idle": "2023-10-25T08:42:00.828392Z",
     "shell.execute_reply": "2023-10-25T08:42:00.827415Z",
     "shell.execute_reply.started": "2023-10-25T08:42:00.661340Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classification Score:  0.65\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dec_tree = DecisionTreeClassifier()\n",
    "dec_tree.fit(x_train,y_train)\n",
    "print(\"Decision Tree Classification Score: \",dec_tree.score(x_test,y_test))\n",
    "method_names.append(\"Decision Tree\")\n",
    "method_scores.append(dec_tree.score(x_test,y_test))\n",
    "\n",
    "#Confusion Matrix\n",
    "y_pred = dec_tree.predict(x_test)\n",
    "conf_mat = confusion_matrix(y_test,y_pred)\n",
    "#Visualization Confusion Matrix\n",
    "f, ax = plt.subplots(figsize=(5,5))\n",
    "sns.heatmap(conf_mat,annot=True,linewidths=0.5,linecolor=\"red\",fmt=\".0f\",ax=ax)\n",
    "plt.xlabel(\"Predicted Values\")\n",
    "plt.ylabel(\"True Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_uuid": "4ad7376894ea8ffa78e4765b778993007a387e70",
    "execution": {
     "iopub.execute_input": "2023-10-25T08:42:00.830358Z",
     "iopub.status.busy": "2023-10-25T08:42:00.829999Z",
     "iopub.status.idle": "2023-10-25T08:42:01.112686Z",
     "shell.execute_reply": "2023-10-25T08:42:01.111674Z",
     "shell.execute_reply.started": "2023-10-25T08:42:00.830298Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classification Score:  0.75\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUUAAAFACAYAAAAruW7uAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAF51JREFUeJzt3XucZVV14PHfaroRhJZXS8v7oYAII+9GJRIYsOWlEMV8YEBBkAaMGuMME8ZgHBxn4gRDIkEDjRBEM404gBIeIhCVh7yRVhDkJQgNaSAQ3grdtfLHPU1vqquqbx3Orfuo35fP+dS9555797oUtVh773P2icxEktQypdsBSFIvMSlKUsGkKEkFk6IkFUyKklQwKUpSwaQoSQWToiQVTIqSVJja7QBGFeGlNlI3ZEadt73y5AO1/manzdi0Vnud0rtJEZg6bd1uh6AaFr3yKAC7rLt7lyNRHdd1O4Au6+mkKKmPDC3udgSNMClKakYOdTuCRpgUJTVjyKQoSa9KK0VJKlgpSlLBSlGSCs4+S1LBSlGSCo4pStJSzj5LUslKUZIKVoqSVHD2WZIKVoqSVHBMUZIKA1IpejsCSSpYKUpqht1nSVoq09lnSVpqQMYUTYqSmmH3WZIKVoqSVPCKFkkqWClKUsExRUkqWClKUqFDlWJEnAXsBzyemVtX+04CPgC8DNwPfDwz/32E9z4IPAcsBhZl5o7La8/L/CQ1Y2io3rZ8ZwN7Ddt3BbB1Zr4TuAf4H2O8f/fM3LadhAgmRUkNyVxca1v+5+bVwFPD9v0oMxdVT28A1m/qe5gUJTWjZqUYEXMi4pZimzPOlo8ALhvltQR+FBG3tvu5jilKakbNiZbMnAvMrfPeiPgLYBHwT6Mc8geZuSAi1gauiIi7q8pzVCZFSc2Y4FNyIuJwWhMwe2RmjnRMZi6ofj4eERcCs4Axk6LdZ0nNyKF6Ww0RsRfw34EPZuaLoxyzSkRMX/IYmA3csbzPNilK6mkRMQ+4HtgiIh6JiCOBU4HptLrEt0fEadWx60bEpdVbZwLXRsR84Cbgksz84fLas/ssqRkd6j5n5sEj7D5zlGMfBfapHj8AbDPe9kyKkprhFS2SVPDaZ0kqmBQlqWD3WZIKVoqSVLBSlKSClaIkFawUJalgpShJBZOiJBVGXqim75gUJTXDSlGSCiZFSSo4+yxJhQGpFF1kVpIKVoqSmuHssyQVBqT7bFKU1AyToiQVnH2WpKVyyDFFSVrK7rMkFew+S1LB7rMkFew+S1LBpChJBa9oUR1nzP0b9t1nTx5/4km23W6PboejcVjxDdP4+vlfY9obpjF1hRX48SU/5cy/+Va3w+odA1IpuiDEBDvnnPPYd79Duh2Ganj596/wmT/+HIe/7ygOm30UO+82i62237LbYfWOoay39ZiOVYoR8XZgf2C9atcC4KLMvKtTbfaDa669kY02Wr/bYaiml178HQBTp05l6rSp5IB0GRsxIKfkdKRSjIg/B84FArip2gKYFxHHd6JNaSJMmTKFs380l4t/cQE3X30Lv/r53d0OqXdYKY7pSGCrzHyl3BkRJwN3Al8Z6U0RMQeYA3B6hwKTXo+hoSEOnz2HVd+0Cn915pfYZIuN+c2vH+x2WD0hHVMc0xCw7gj716leG1Fmzs3MHTNzxzkdCkxqwvPPvsBt193Ou3ab1e1Q1LBOVYqfBa6KiHuBh6t9GwJvAz7VoTaljlp9zdVYtGgRzz/7AiuutCI77boD3/nGud0Oq3f0YFe4jo4kxcz8YURsDszitRMtN2fm4k602S++8+2v84e7vpsZM9bkwQdu4cQvfZV/PNs/rH6w1sy1OOHv/pwpU6YwZcoU/uWff8LPrryh22H1jgGZaOnY7HNmDgH+FzPMoR/9k26HoJruv+sBPv7+o7sdRu+yUpSkwoBMtJgUJTXDSlGSCo4pSlLBSlGSlhqUk7dNipKaYaUoSYUBSYouHSapGTlUb1uOiDgrIh6PiDuKfWtGxBURcW/1c41R3ntYdcy9EXFYO1/DpCipGZ1bJedsYK9h+44HrsrMzYCrquevERFrAl8EdqZ1dd0XR0ueJZOipEbkUNbalvu5mVcDTw3bvT+wZNnzbwEHjPDW9wNXZOZTmfk0cAXLJtdlOKYoqRkTO6Y4MzMfqx7/KzBzhGPWY+mCNACPsHQthlGZFCU1o+YpOeU6qpW5mTm33fdnZkZEYxnZpCipGTUrxSoBtp0EKwsjYp3MfCwi1gEeH+GYBcBuxfP1gZ8s74MdU5TUjIm9HcFFwJLZ5MOAH4xwzOXA7IhYo5pgmV3tG5NJUVJPi4h5wPXAFhHxSEQcSeuWJu+rFrLes3pOROwYEd8EyMyngP8F3FxtX6r2jcnus6RGdOrOhpl58CgvLXPj9My8BfhE8fws4KzxtGdSlNSMAbmixaQoqRkmRUlaqp0TsfuBSVFSM0yKklQYjOUUTYqSmmH3WZJKJkVJKth9lqSl7D5LUslKUZKWslKUpJKVoiQt1cY9qPqCSVFSM0yKkrTUoFSKLjIrSQUrRUnNGJBK0aQoqRGD0n02KUpqxKAkxeWOKUbEpyLiTdXj0yPipohY5t4Ikia3HKq39Zp2JlrmZOazETEbmAkcBfx1Z8OS1Hcy6m09pp3u85Jrd/YBvp2Z8yPCWWtJr9GLVV8d7STF+RFxKbA58PmIWJWliVKSAMih3qv66mgnKX4c2AG4LzNfjIgZwJGdDUtSvxmUSnG53eDMXAxsChxb7Vq5nfdJmlwyo9bWa9qZfT4V2B04tNr1AnBaJ4OS1H8GZfa5ne7zezJz+4j4OUBmPhURK3Y4Lkl9ZjKNKb5SzTYnQESsxcBc0COpKTkg06/tJMWvA+cDb46IE4E/Bk7saFSS+s6kqRQz85yIuBXYEwjgI5l5R8cjk9RXJk1SjIh1gaeB75X7MvPRTgYmqb9Mpu7zVSw9WXtlYAPgfmCLTgUlqf9MmkoxM7csn0fELOATHYtIkrpo3CdhZ+ZNwLs6EIukPjYoJ2+3M6b4meLpFFqX/C3sWESS+lIvnohdRztjim8uHi8CrqSYdJEkgKEerPrqaGdM8QsTEYik/taLXeE6Rk2KEXEhYywRlpkf6khEkvrSZJh9PnXCopDU9wb+PMXMvGoiA5HU3yZDpQhARLwV+N/AO4CVluzPzM07GJekPjMoEy3tnKd4NvCPtK573hs4D/huB2OS1IcG5TzFdpLiGzPzcoDMvD8zT6CVHCXpVZn1tl7TznmKv6/WU7w/Io4BFgDTOxuWpH4zmbrPfwasAnwG2IXWdc9HdDIoSf2nU93niNgiIm4vtmcj4rPDjtktIp4pjvnLut9jrPMU/wi4JDNvrHY9B3y0bkOSBlunusKZ+WtgW4CIWIFWb/XCEQ69JjP3e73tjdV9PgI4PSIuAeYBV2ZO7NWNi15xycZ+dt2jP+52CJpAE9R93gO4PzMf6lQDo3afM/MDwObAtcBxwMMRcWpE7NKpYCT1r7rd54iYExG3FNucMZo5iFaRNpJ3R8T8iLgsIraq+z0i26x5I2Jt4CPA0cD0zNykbqNtNpgbrrF1R5tQZ/z26dbdKl554v4uR6I6ps3YtFbJd+O6H6rVgd750Qvaaq+6i+ijwFaZuXDYa28ChjLz+YjYB/haZm5WJ5621lOMiNWAfYH9gbWAi+s0Jkmvw97AbcMTIkBmPpuZz1ePLwWmRcSMOo2MNdHyRlpJ8GBgFnAJcBJw1USPLUrqfRNwyuHBjNJ1joi3AAszM6u7A0wB/q1OI2NNtPyW1tqJZwEHZubLdRqQNDl0cqIlIlYB3kdr+G7JvmMAMvM04EDg2IhYBLwEHJTtjg0OM1ZS3HhJOSpJy9PJS/Yy8wVaQ3flvtOKx6fS0MpeY62SY0KU1LZBGVNr5zI/SVquZDAu82s7KUbEGzLz950MRlL/GurBxR3qWO4pORExKyJ+CdxbPd8mIv6+45FJ6itDRK2t17RznuIpwH5U09uZOR/YvZNBSeo/SdTaek073ecpmflQxGuCX9yheCT1qck00fJwdTJkVitUfBq4p7NhSeo3vVj11dFOUjyWVhd6Q2AhrRO6j+1kUJL6z6SpFDPzcVorU0jSqCZNUoyIMxjhssbMHGt5H0mTzGTqPl9ZPF4J+CPg4c6EI6lfDchtn9vqPr/mdqYR8W1aC89K0qt68ZzDOupc5rcJMLPpQCT1twG5oKWtMcWnWfp9pwBPAcd3MihJ6pYxk2K0ztjehtbds6C13Peg/A9BUoMmxexztYrtpZnpzVIkjWkoBmNMsZ1rn2+PiO06HomkvpY1t14z1j1apmbmImA74OaIuB94AQhaReT2ExSjpD4wGbrPNwHbAx+coFgk9bHJcJ5iAGSmN++VtFyT4TzFN0fE50Z7MTNP7kA8kvpUL44P1jFWUlwBWBUGJP1L6qjJ0H1+LDO/NGGRSOprk2GiZUDyvqSJMBm6z3tMWBSS+t7Ad58z86mJDERSf5sM3WdJaptJUZIKOejdZ0kaDytFSSqYFCWpMCin5LSzdJgkTRpWipIaMfDnKUrSeDimKEkFk6IkFQZlosWkKKkRjilKUsHusyQV7D5LUmFoQNKiSVFSI+w+S1JhMOpEk6KkhlgpSlKhk6fkRMSDwHPAYmBRZu447PUAvgbsA7wIHJ6Zt9Vpy6QoqRETMNGye2Y+OcprewObVdvOwD9UP8fNVXIkNSJrbg3ZHzgnW24AVo+Idep8kElRUiOGam4RMScibim2OSN8fAI/iohbR3l9PeDh4vkj1b5xs/ssqRF1u8+ZOReYu5zD/iAzF0TE2sAVEXF3Zl5dq8HlsFKU1PMyc0H183HgQmDWsEMWABsUz9ev9o2bSVFSIzo1phgRq0TE9CWPgdnAHcMOuwj4WLS8C3gmMx+r8z3sPktqRAfPU5wJXNg664apwP/LzB9GxDEAmXkacCmt03Huo3VKzsfrNmZSlNSITp2Sk5kPANuMsP+04nECf9JEeyZFSY3wMj9JKniZnyQVckBqRZOipEZYKUpSwUVmJakwGCnRk7cn3DrrzeTcH5zJVdd/nyt/diFHHH1It0PSGE74Pyez674HccChxyzz2tnzzmfrXfbm6X9/pguR9Z4hstbWa0yKE2zxosV8+QtfZY93H8D+sw/hY0cexGZbbNrtsDSKA/Z5H6ed/OVl9j+28Al+dtNtrDNz7S5E1ZvqLgjRa0yKE+zxhU9yxy/uAuCF51/kvnt+w1vWmdnlqDSaHbf9T6z2punL7P/rU07nc588khiQex03IWv+02smPClGRO3LbwbN+husy1bvfDs/v/UX3Q5F4/Av11zP2m+ewds3s8IvWSnWd+JoL5Trqi1vHaF+98ZVVub0b/0tJ37+//L8cy90Oxy16aXf/Y4zzvkun/rER7sdSs8ZlEqxI7PPETFa6RO0Lu4e0WvWVYvIZUdyBsPUqVM5/Vt/y4X//xJ+ePFV3Q5H4/DwgsdY8Oi/8uHDPgnAwiee5CNHfJpzz/g7Zqy1Zpej665erPrq6NQpOTOB9wNPD9sfwM861GbfOOmUE7nvngf45jfO6XYoGqfN37oJV19y7qvPZ3/4ML575imssfpqXYyqNwxl71V9dXSq+3wxsGpmPjRsexD4SYfa7As77bwdHz7og7znvTtz2U+/x2U//R677/neboelURz3xa9wyNF/xoO/fYQ9DjiU8//58m6HpA6L7NXsHpEbrrF1t6NQDb99urX+5ytP3N/lSFTHtBmb1ppTP3SjD9VKJt956IKemsP3ihZJjejFE7HrMClKakQvziTXYVKU1AhnnyWpYPdZkgp2nyWpYPdZkgo9e3rfOJkUJTXCMUVJKth9lqSCEy2SVLD7LEkFJ1okqeCYoiQVHFOUpMKgjCl6Nz9JKlgpSmqEEy2SVBiU7rNJUVIjnGiRpMKg3M3PpCipEYOREk2KkhrimKIkFUyKklTwlBxJKlgpSlLBU3IkqWD3WZIKg9J9dkEISY3IzFrb8kTEBhHx44j4VUTcGRF/OsIxu0XEMxFxe7X9Zd3vYaUoqREdrBQXAf81M2+LiOnArRFxRWb+athx12Tmfq+3MZOipEZ0aqIlMx8DHqsePxcRdwHrAcOTYiPsPktqxFBmrS0i5kTELcU2Z7Q2ImJjYDvgxhFefndEzI+IyyJiq7rfw0pRUldl5lxg7vKOi4hVgfOBz2bms8Nevg3YKDOfj4h9gO8Dm9WJx0pRUiOy5j/tiIhptBLiP2XmBcu0nflsZj5fPb4UmBYRM+p8DytFSY3o1NJhERHAmcBdmXnyKMe8BViYmRkRs2gVfP9Wpz2ToqRGdPCKll2AjwK/jIjbq32fBzYEyMzTgAOBYyNiEfAScFDWPJvcpCipEZ2qFDPzWiCWc8ypwKlNtGdSlNQIr32WpIK3I5CkgpWiJBUyh7odQiNMipIaMSir5JgUJTXC9RQlqWClKEkFK0VJKnhKjiQVPCVHkgp2nyWp4ESLJBUGpVJ0kVlJKlgpSmqEs8+SVBiU7rNJUVIjnGiRpIKVoiQVHFOUpIJXtEhSwUpRkgqOKUpSwe6zJBWsFCWpMChJMXr2i0T0aGDSgMuMOm+buuJ6tf5mF728oFZ7ndK7SXHARcSczJzb7ThUj7+/weUqOd0zp9sB6HXx9zegTIqSVDApSlLBpNg9jkf1N39/A8qJFkkqWClKUsGkKEkFk2IXRMReEfHriLgvIo7vdjxqX0ScFRGPR8Qd3Y5FnWFSnGARsQLwdWBv4B3AwRHxju5GpXE4G9ir20Goc0yKE28WcF9mPpCZLwPnAvt3OSa1KTOvBp7qdhzqHJPixFsPeLh4/ki1T1IPMClKUsGkOPEWABsUz9ev9knqASbFiXczsFlEbBIRKwIHARd1OSZJFZPiBMvMRcCngMuBu4DzMvPO7kaldkXEPOB6YIuIeCQijux2TGqWl/lJUsFKUZIKJkVJKpgUJalgUpSkgklRkgomxT4UEYsj4vaIuCMivhcRb3wdn7VbRFxcPf7gWKv2RMTqEfHJGm38z4j4b8P2/WFEXD9s39SIWBgR647ns6QmmRT700uZuW1mbg28DBxTvhgt4/7dZuZFmfmVMQ5ZHRh3UhzFNcD6EbFRsW9P4M7MfLShNqRxMyn2v2uAt0XExtUajecAdwAbRMTsiLg+Im6rKspV4dX1HO+OiNuADy35oIg4PCJOrR7PjIgLI2J+tb0H+Arw1qpKPak67riIuDkifhERJxaf9RcRcU9EXAtsMTzozBwCzqN1Rc8SBwHzqvcfVX3u/Ig4f6RqOCJ+EhE7Vo9nRMSD1eMVIuKkIq6jq/3rRMTVRZX93rr/0jW4TIp9LCKm0lqX8ZfVrs2Ab2TmVsALwAnAnpm5PXAL8LmIWAk4A/gAsAPwllE+/hTgp5m5DbA9cCdwPHB/VaUeFxGzqzZnAdsCO0TErhGxA60Ety2wD7DTKG3Mq44jIt5QHXt+9doFmblT1f5dwHiuHDkSeCYzd6raPioiNgH+C3B5Zm4LbAPcPo7P1CQxtdsBqJaVI2LJH/Q1wJnAusBDmXlDtf9dtBaxvS4iAFakdXna24HfZOa9ABHxHUa+sft/Bj4GkJmLgWciYo1hx8yutp9Xz1ellSSnAxdm5otVGyNe252Zt0TEqhGxBbAlcGNmLlmrcOuI+DKtLvuqtC6LbNds4J0RcWD1fLUqrpuBsyJiGvD9zDQpahkmxf70UlXtvKpKfC+Uu4ArMvPgYce95n2vUwB/lZmnD2vjs+P4jCXV4pbV4yXOBg7IzPkRcTiw2wjvXcTS3s5Kw+L6dGYuk0gjYldgX+DsiDg5M88ZR6yaBOw+D64bgF0i4m0AEbFKRGwO3A1sHBFvrY47eJT3XwUcW713hYhYDXiOVhW4xOXAEcVY5XoRsTZwNXBARKwcEdNpddVHMw84lFZl+oNi/3TgsaqqO2SU9z5IawgA4MBi/+XAsdV7iYjNq++/EbAwM88AvklrWEB6DSvFAZWZT1QV1rxqvA7ghMy8JyLmAJdExIu0ut/TR/iIPwXmVqvALAaOzczrI+K66qZNl1XjilsC11eV6vPAoZl5W0R8F5gPPE6r2zpanHdFxAvArZlZVrpfAG4Enqh+jhTjV4HzlnyfYv83gY2B26IV2BPAAbSqzeMi4pUq1o+NFpcmL1fJkaSC3WdJKpgUJalgUpSkgklRkgomRUkqmBQlqWBSlKTCfwDvH24lZSWCgwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rand_forest = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rand_forest.fit(x_train,y_train)\n",
    "print(\"Random Forest Classification Score: \",rand_forest.score(x_test,y_test))\n",
    "method_names.append(\"Random Forest\")\n",
    "method_scores.append(rand_forest.score(x_test,y_test))\n",
    "\n",
    "#Confusion Matrix\n",
    "y_pred = rand_forest.predict(x_test)\n",
    "conf_mat = confusion_matrix(y_test,y_pred)\n",
    "#Visualization Confusion Matrix\n",
    "f, ax = plt.subplots(figsize=(5,5))\n",
    "sns.heatmap(conf_mat,annot=True,linewidths=0.5,linecolor=\"red\",fmt=\".0f\",ax=ax)\n",
    "plt.xlabel(\"Predicted Values\")\n",
    "plt.ylabel(\"True Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_uuid": "d93408822f4b3d162ec6ad75cbaaafbebf663692",
    "execution": {
     "iopub.execute_input": "2023-10-25T08:42:01.116795Z",
     "iopub.status.busy": "2023-10-25T08:42:01.116470Z",
     "iopub.status.idle": "2023-10-25T08:42:08.263103Z",
     "shell.execute_reply": "2023-10-25T08:42:08.262148Z",
     "shell.execute_reply.started": "2023-10-25T08:42:01.116728Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.6932 - acc: 0.4528\n",
      "Epoch 2/200\n",
      "53/53 [==============================] - 0s 89us/step - loss: 0.6931 - acc: 0.6415\n",
      "Epoch 3/200\n",
      "53/53 [==============================] - 0s 91us/step - loss: 0.6930 - acc: 0.5472\n",
      "Epoch 4/200\n",
      "53/53 [==============================] - 0s 89us/step - loss: 0.6928 - acc: 0.5472\n",
      "Epoch 5/200\n",
      "53/53 [==============================] - 0s 86us/step - loss: 0.6927 - acc: 0.5472\n",
      "Epoch 6/200\n",
      "53/53 [==============================] - 0s 84us/step - loss: 0.6926 - acc: 0.5472\n",
      "Epoch 7/200\n",
      "53/53 [==============================] - 0s 89us/step - loss: 0.6924 - acc: 0.5472\n",
      "Epoch 8/200\n",
      "53/53 [==============================] - 0s 90us/step - loss: 0.6922 - acc: 0.5472\n",
      "Epoch 9/200\n",
      "53/53 [==============================] - 0s 89us/step - loss: 0.6921 - acc: 0.5472\n",
      "Epoch 10/200\n",
      "53/53 [==============================] - 0s 85us/step - loss: 0.6919 - acc: 0.5472\n",
      "Epoch 11/200\n",
      "53/53 [==============================] - 0s 107us/step - loss: 0.6917 - acc: 0.5472\n",
      "Epoch 12/200\n",
      "53/53 [==============================] - 0s 98us/step - loss: 0.6915 - acc: 0.5472\n",
      "Epoch 13/200\n",
      "53/53 [==============================] - 0s 88us/step - loss: 0.6912 - acc: 0.5472\n",
      "Epoch 14/200\n",
      "53/53 [==============================] - 0s 102us/step - loss: 0.6909 - acc: 0.5472\n",
      "Epoch 15/200\n",
      "53/53 [==============================] - 0s 101us/step - loss: 0.6906 - acc: 0.5472\n",
      "Epoch 16/200\n",
      "53/53 [==============================] - 0s 88us/step - loss: 0.6902 - acc: 0.5472\n",
      "Epoch 17/200\n",
      "53/53 [==============================] - 0s 107us/step - loss: 0.6898 - acc: 0.5472\n",
      "Epoch 18/200\n",
      "53/53 [==============================] - 0s 88us/step - loss: 0.6894 - acc: 0.5472\n",
      "Epoch 19/200\n",
      "53/53 [==============================] - 0s 79us/step - loss: 0.6889 - acc: 0.5472\n",
      "Epoch 20/200\n",
      "53/53 [==============================] - 0s 80us/step - loss: 0.6883 - acc: 0.5472\n",
      "Epoch 21/200\n",
      "53/53 [==============================] - 0s 67us/step - loss: 0.6877 - acc: 0.5472\n",
      "Epoch 22/200\n",
      "53/53 [==============================] - 0s 77us/step - loss: 0.6869 - acc: 0.5472\n",
      "Epoch 23/200\n",
      "53/53 [==============================] - 0s 93us/step - loss: 0.6861 - acc: 0.5472\n",
      "Epoch 24/200\n",
      "53/53 [==============================] - 0s 91us/step - loss: 0.6852 - acc: 0.5472\n",
      "Epoch 25/200\n",
      "53/53 [==============================] - 0s 83us/step - loss: 0.6842 - acc: 0.5660\n",
      "Epoch 26/200\n",
      "53/53 [==============================] - 0s 76us/step - loss: 0.6831 - acc: 0.6038\n",
      "Epoch 27/200\n",
      "53/53 [==============================] - 0s 74us/step - loss: 0.6818 - acc: 0.6226\n",
      "Epoch 28/200\n",
      "53/53 [==============================] - 0s 79us/step - loss: 0.6804 - acc: 0.6415\n",
      "Epoch 29/200\n",
      "53/53 [==============================] - 0s 100us/step - loss: 0.6791 - acc: 0.6415\n",
      "Epoch 30/200\n",
      "53/53 [==============================] - 0s 75us/step - loss: 0.6775 - acc: 0.6604\n",
      "Epoch 31/200\n",
      "53/53 [==============================] - 0s 76us/step - loss: 0.6757 - acc: 0.7170\n",
      "Epoch 32/200\n",
      "53/53 [==============================] - 0s 81us/step - loss: 0.6738 - acc: 0.7358\n",
      "Epoch 33/200\n",
      "53/53 [==============================] - 0s 103us/step - loss: 0.6720 - acc: 0.7547\n",
      "Epoch 34/200\n",
      "53/53 [==============================] - 0s 74us/step - loss: 0.6697 - acc: 0.7736\n",
      "Epoch 35/200\n",
      "53/53 [==============================] - 0s 59us/step - loss: 0.6677 - acc: 0.7925\n",
      "Epoch 36/200\n",
      "53/53 [==============================] - 0s 79us/step - loss: 0.6652 - acc: 0.7925\n",
      "Epoch 37/200\n",
      "53/53 [==============================] - 0s 78us/step - loss: 0.6627 - acc: 0.7925\n",
      "Epoch 38/200\n",
      "53/53 [==============================] - 0s 82us/step - loss: 0.6598 - acc: 0.8302\n",
      "Epoch 39/200\n",
      "53/53 [==============================] - 0s 71us/step - loss: 0.6570 - acc: 0.8491\n",
      "Epoch 40/200\n",
      "53/53 [==============================] - 0s 82us/step - loss: 0.6538 - acc: 0.8679\n",
      "Epoch 41/200\n",
      "53/53 [==============================] - 0s 82us/step - loss: 0.6504 - acc: 0.8679\n",
      "Epoch 42/200\n",
      "53/53 [==============================] - 0s 83us/step - loss: 0.6467 - acc: 0.8679\n",
      "Epoch 43/200\n",
      "53/53 [==============================] - 0s 67us/step - loss: 0.6429 - acc: 0.8679\n",
      "Epoch 44/200\n",
      "53/53 [==============================] - 0s 85us/step - loss: 0.6391 - acc: 0.8679\n",
      "Epoch 45/200\n",
      "53/53 [==============================] - 0s 71us/step - loss: 0.6350 - acc: 0.8679\n",
      "Epoch 46/200\n",
      "53/53 [==============================] - 0s 75us/step - loss: 0.6303 - acc: 0.8868\n",
      "Epoch 47/200\n",
      "53/53 [==============================] - 0s 80us/step - loss: 0.6256 - acc: 0.8868\n",
      "Epoch 48/200\n",
      "53/53 [==============================] - 0s 93us/step - loss: 0.6210 - acc: 0.8868\n",
      "Epoch 49/200\n",
      "53/53 [==============================] - 0s 85us/step - loss: 0.6161 - acc: 0.8868\n",
      "Epoch 50/200\n",
      "53/53 [==============================] - 0s 81us/step - loss: 0.6106 - acc: 0.8868\n",
      "Epoch 51/200\n",
      "53/53 [==============================] - 0s 83us/step - loss: 0.6050 - acc: 0.8868\n",
      "Epoch 52/200\n",
      "53/53 [==============================] - 0s 90us/step - loss: 0.5997 - acc: 0.8868\n",
      "Epoch 53/200\n",
      "53/53 [==============================] - 0s 84us/step - loss: 0.5935 - acc: 0.9057\n",
      "Epoch 54/200\n",
      "53/53 [==============================] - 0s 104us/step - loss: 0.5873 - acc: 0.9057\n",
      "Epoch 55/200\n",
      "53/53 [==============================] - 0s 105us/step - loss: 0.5811 - acc: 0.8868\n",
      "Epoch 56/200\n",
      "53/53 [==============================] - 0s 84us/step - loss: 0.5752 - acc: 0.8868\n",
      "Epoch 57/200\n",
      "53/53 [==============================] - 0s 74us/step - loss: 0.5684 - acc: 0.8868\n",
      "Epoch 58/200\n",
      "53/53 [==============================] - 0s 65us/step - loss: 0.5619 - acc: 0.8868\n",
      "Epoch 59/200\n",
      "53/53 [==============================] - 0s 79us/step - loss: 0.5549 - acc: 0.8868\n",
      "Epoch 60/200\n",
      "53/53 [==============================] - 0s 86us/step - loss: 0.5479 - acc: 0.8868\n",
      "Epoch 61/200\n",
      "53/53 [==============================] - 0s 74us/step - loss: 0.5411 - acc: 0.8868\n",
      "Epoch 62/200\n",
      "53/53 [==============================] - 0s 73us/step - loss: 0.5335 - acc: 0.8868\n",
      "Epoch 63/200\n",
      "53/53 [==============================] - 0s 83us/step - loss: 0.5264 - acc: 0.8868\n",
      "Epoch 64/200\n",
      "53/53 [==============================] - 0s 90us/step - loss: 0.5195 - acc: 0.8868\n",
      "Epoch 65/200\n",
      "53/53 [==============================] - 0s 76us/step - loss: 0.5124 - acc: 0.8868\n",
      "Epoch 66/200\n",
      "53/53 [==============================] - 0s 73us/step - loss: 0.5043 - acc: 0.8868\n",
      "Epoch 67/200\n",
      "53/53 [==============================] - 0s 87us/step - loss: 0.4978 - acc: 0.8868\n",
      "Epoch 68/200\n",
      "53/53 [==============================] - 0s 69us/step - loss: 0.4904 - acc: 0.8868\n",
      "Epoch 69/200\n",
      "53/53 [==============================] - 0s 83us/step - loss: 0.4829 - acc: 0.8868\n",
      "Epoch 70/200\n",
      "53/53 [==============================] - 0s 71us/step - loss: 0.4758 - acc: 0.8868\n",
      "Epoch 71/200\n",
      "53/53 [==============================] - 0s 74us/step - loss: 0.4688 - acc: 0.8868\n",
      "Epoch 72/200\n",
      "53/53 [==============================] - 0s 69us/step - loss: 0.4618 - acc: 0.8868\n",
      "Epoch 73/200\n",
      "53/53 [==============================] - 0s 88us/step - loss: 0.4551 - acc: 0.8868\n",
      "Epoch 74/200\n",
      "53/53 [==============================] - 0s 63us/step - loss: 0.4486 - acc: 0.8868\n",
      "Epoch 75/200\n",
      "53/53 [==============================] - 0s 66us/step - loss: 0.4418 - acc: 0.8868\n",
      "Epoch 76/200\n",
      "53/53 [==============================] - 0s 84us/step - loss: 0.4357 - acc: 0.8868\n",
      "Epoch 77/200\n",
      "53/53 [==============================] - 0s 87us/step - loss: 0.4289 - acc: 0.8868\n",
      "Epoch 78/200\n",
      "53/53 [==============================] - 0s 73us/step - loss: 0.4235 - acc: 0.8868\n",
      "Epoch 79/200\n",
      "53/53 [==============================] - 0s 128us/step - loss: 0.4163 - acc: 0.8868\n",
      "Epoch 80/200\n",
      "53/53 [==============================] - 0s 84us/step - loss: 0.4104 - acc: 0.8868\n",
      "Epoch 81/200\n",
      "53/53 [==============================] - 0s 90us/step - loss: 0.4052 - acc: 0.9057\n",
      "Epoch 82/200\n",
      "53/53 [==============================] - 0s 78us/step - loss: 0.3999 - acc: 0.9057\n",
      "Epoch 83/200\n",
      "53/53 [==============================] - 0s 84us/step - loss: 0.3957 - acc: 0.9057\n",
      "Epoch 84/200\n",
      "53/53 [==============================] - 0s 71us/step - loss: 0.3900 - acc: 0.9057\n",
      "Epoch 85/200\n",
      "53/53 [==============================] - 0s 91us/step - loss: 0.3852 - acc: 0.9057\n",
      "Epoch 86/200\n",
      "53/53 [==============================] - 0s 71us/step - loss: 0.3801 - acc: 0.9057\n",
      "Epoch 87/200\n",
      "53/53 [==============================] - 0s 75us/step - loss: 0.3758 - acc: 0.9057\n",
      "Epoch 88/200\n",
      "53/53 [==============================] - 0s 74us/step - loss: 0.3708 - acc: 0.9057\n",
      "Epoch 89/200\n",
      "53/53 [==============================] - 0s 95us/step - loss: 0.3669 - acc: 0.9057\n",
      "Epoch 90/200\n",
      "53/53 [==============================] - 0s 83us/step - loss: 0.3628 - acc: 0.9057\n",
      "Epoch 91/200\n",
      "53/53 [==============================] - 0s 71us/step - loss: 0.3586 - acc: 0.9057\n",
      "Epoch 92/200\n",
      "53/53 [==============================] - 0s 78us/step - loss: 0.3552 - acc: 0.9057\n",
      "Epoch 93/200\n",
      "53/53 [==============================] - 0s 79us/step - loss: 0.3514 - acc: 0.9057\n",
      "Epoch 94/200\n",
      "53/53 [==============================] - 0s 70us/step - loss: 0.3477 - acc: 0.9057\n",
      "Epoch 95/200\n",
      "53/53 [==============================] - 0s 78us/step - loss: 0.3442 - acc: 0.9057\n",
      "Epoch 96/200\n",
      "53/53 [==============================] - 0s 81us/step - loss: 0.3407 - acc: 0.9057\n",
      "Epoch 97/200\n",
      "53/53 [==============================] - 0s 76us/step - loss: 0.3375 - acc: 0.9057\n",
      "Epoch 98/200\n",
      "53/53 [==============================] - 0s 87us/step - loss: 0.3348 - acc: 0.9057\n",
      "Epoch 99/200\n",
      "53/53 [==============================] - 0s 108us/step - loss: 0.3316 - acc: 0.9057\n",
      "Epoch 100/200\n",
      "53/53 [==============================] - 0s 83us/step - loss: 0.3285 - acc: 0.9057\n",
      "Epoch 101/200\n",
      "53/53 [==============================] - 0s 77us/step - loss: 0.3257 - acc: 0.9057\n",
      "Epoch 102/200\n",
      "53/53 [==============================] - 0s 75us/step - loss: 0.3228 - acc: 0.9245\n",
      "Epoch 103/200\n",
      "53/53 [==============================] - 0s 75us/step - loss: 0.3199 - acc: 0.9057\n",
      "Epoch 104/200\n",
      "53/53 [==============================] - 0s 70us/step - loss: 0.3176 - acc: 0.9245\n",
      "Epoch 105/200\n",
      "53/53 [==============================] - 0s 96us/step - loss: 0.3145 - acc: 0.9245\n",
      "Epoch 106/200\n",
      "53/53 [==============================] - 0s 72us/step - loss: 0.3123 - acc: 0.9057\n",
      "Epoch 107/200\n",
      "53/53 [==============================] - 0s 71us/step - loss: 0.3100 - acc: 0.9057\n",
      "Epoch 108/200\n",
      "53/53 [==============================] - 0s 67us/step - loss: 0.3081 - acc: 0.9057\n",
      "Epoch 109/200\n",
      "53/53 [==============================] - 0s 70us/step - loss: 0.3054 - acc: 0.9057\n",
      "Epoch 110/200\n",
      "53/53 [==============================] - 0s 79us/step - loss: 0.3035 - acc: 0.9057\n",
      "Epoch 111/200\n",
      "53/53 [==============================] - 0s 80us/step - loss: 0.3009 - acc: 0.9057\n",
      "Epoch 112/200\n",
      "53/53 [==============================] - 0s 75us/step - loss: 0.2996 - acc: 0.9245\n",
      "Epoch 113/200\n",
      "53/53 [==============================] - 0s 97us/step - loss: 0.2967 - acc: 0.9245\n",
      "Epoch 114/200\n",
      "53/53 [==============================] - 0s 91us/step - loss: 0.2947 - acc: 0.9245\n",
      "Epoch 115/200\n",
      "53/53 [==============================] - 0s 79us/step - loss: 0.2930 - acc: 0.9245\n",
      "Epoch 116/200\n",
      "53/53 [==============================] - 0s 79us/step - loss: 0.2911 - acc: 0.9245\n",
      "Epoch 117/200\n",
      "53/53 [==============================] - 0s 110us/step - loss: 0.2892 - acc: 0.9245\n",
      "Epoch 118/200\n",
      "53/53 [==============================] - 0s 81us/step - loss: 0.2874 - acc: 0.9245\n",
      "Epoch 119/200\n",
      "53/53 [==============================] - 0s 76us/step - loss: 0.2854 - acc: 0.9245\n",
      "Epoch 120/200\n",
      "53/53 [==============================] - 0s 85us/step - loss: 0.2836 - acc: 0.9245\n",
      "Epoch 121/200\n",
      "53/53 [==============================] - 0s 88us/step - loss: 0.2819 - acc: 0.9245\n",
      "Epoch 122/200\n",
      "53/53 [==============================] - 0s 87us/step - loss: 0.2804 - acc: 0.9245\n",
      "Epoch 123/200\n",
      "53/53 [==============================] - 0s 105us/step - loss: 0.2801 - acc: 0.9245\n",
      "Epoch 124/200\n",
      "53/53 [==============================] - 0s 93us/step - loss: 0.2779 - acc: 0.9245\n",
      "Epoch 125/200\n",
      "53/53 [==============================] - 0s 92us/step - loss: 0.2767 - acc: 0.9245\n",
      "Epoch 126/200\n",
      "53/53 [==============================] - 0s 97us/step - loss: 0.2743 - acc: 0.9245\n",
      "Epoch 127/200\n",
      "53/53 [==============================] - 0s 80us/step - loss: 0.2731 - acc: 0.9245\n",
      "Epoch 128/200\n",
      "53/53 [==============================] - 0s 72us/step - loss: 0.2716 - acc: 0.9245\n",
      "Epoch 129/200\n",
      "53/53 [==============================] - 0s 85us/step - loss: 0.2703 - acc: 0.9245\n",
      "Epoch 130/200\n",
      "53/53 [==============================] - 0s 86us/step - loss: 0.2690 - acc: 0.9245\n",
      "Epoch 131/200\n",
      "53/53 [==============================] - 0s 93us/step - loss: 0.2679 - acc: 0.9245\n",
      "Epoch 132/200\n",
      "53/53 [==============================] - 0s 89us/step - loss: 0.2666 - acc: 0.9245\n",
      "Epoch 133/200\n",
      "53/53 [==============================] - 0s 92us/step - loss: 0.2654 - acc: 0.9245\n",
      "Epoch 134/200\n",
      "53/53 [==============================] - 0s 83us/step - loss: 0.2642 - acc: 0.9245\n",
      "Epoch 135/200\n",
      "53/53 [==============================] - 0s 113us/step - loss: 0.2629 - acc: 0.9245\n",
      "Epoch 136/200\n",
      "53/53 [==============================] - 0s 84us/step - loss: 0.2621 - acc: 0.9245\n",
      "Epoch 137/200\n",
      "53/53 [==============================] - 0s 82us/step - loss: 0.2606 - acc: 0.9245\n",
      "Epoch 138/200\n",
      "53/53 [==============================] - 0s 110us/step - loss: 0.2599 - acc: 0.9245\n",
      "Epoch 139/200\n",
      "53/53 [==============================] - 0s 98us/step - loss: 0.2587 - acc: 0.9245\n",
      "Epoch 140/200\n",
      "53/53 [==============================] - 0s 100us/step - loss: 0.2577 - acc: 0.9245\n",
      "Epoch 141/200\n",
      "53/53 [==============================] - 0s 101us/step - loss: 0.2566 - acc: 0.9245\n",
      "Epoch 142/200\n",
      "53/53 [==============================] - 0s 88us/step - loss: 0.2561 - acc: 0.9245\n",
      "Epoch 143/200\n",
      "53/53 [==============================] - 0s 81us/step - loss: 0.2548 - acc: 0.9245\n",
      "Epoch 144/200\n",
      "53/53 [==============================] - 0s 102us/step - loss: 0.2538 - acc: 0.9245\n",
      "Epoch 145/200\n",
      "53/53 [==============================] - 0s 98us/step - loss: 0.2528 - acc: 0.9245\n",
      "Epoch 146/200\n",
      "53/53 [==============================] - 0s 111us/step - loss: 0.2518 - acc: 0.9245\n",
      "Epoch 147/200\n",
      "53/53 [==============================] - 0s 100us/step - loss: 0.2511 - acc: 0.9245\n",
      "Epoch 148/200\n",
      "53/53 [==============================] - 0s 97us/step - loss: 0.2502 - acc: 0.9245\n",
      "Epoch 149/200\n",
      "53/53 [==============================] - 0s 113us/step - loss: 0.2496 - acc: 0.9245\n",
      "Epoch 150/200\n",
      "53/53 [==============================] - 0s 114us/step - loss: 0.2492 - acc: 0.9245\n",
      "Epoch 151/200\n",
      "53/53 [==============================] - 0s 111us/step - loss: 0.2482 - acc: 0.9245\n",
      "Epoch 152/200\n",
      "53/53 [==============================] - 0s 101us/step - loss: 0.2472 - acc: 0.9245\n",
      "Epoch 153/200\n",
      "53/53 [==============================] - 0s 114us/step - loss: 0.2463 - acc: 0.9245\n",
      "Epoch 154/200\n",
      "53/53 [==============================] - 0s 103us/step - loss: 0.2458 - acc: 0.9245\n",
      "Epoch 155/200\n",
      "53/53 [==============================] - 0s 125us/step - loss: 0.2448 - acc: 0.9245\n",
      "Epoch 156/200\n",
      "53/53 [==============================] - 0s 134us/step - loss: 0.2437 - acc: 0.9245\n",
      "Epoch 157/200\n",
      "53/53 [==============================] - 0s 113us/step - loss: 0.2431 - acc: 0.9245\n",
      "Epoch 158/200\n",
      "53/53 [==============================] - 0s 114us/step - loss: 0.2424 - acc: 0.9245\n",
      "Epoch 159/200\n",
      "53/53 [==============================] - 0s 95us/step - loss: 0.2419 - acc: 0.9245\n",
      "Epoch 160/200\n",
      "53/53 [==============================] - 0s 113us/step - loss: 0.2414 - acc: 0.9245\n",
      "Epoch 161/200\n",
      "53/53 [==============================] - 0s 106us/step - loss: 0.2406 - acc: 0.9245\n",
      "Epoch 162/200\n",
      "53/53 [==============================] - 0s 103us/step - loss: 0.2398 - acc: 0.9245\n",
      "Epoch 163/200\n",
      "53/53 [==============================] - 0s 88us/step - loss: 0.2390 - acc: 0.9245\n",
      "Epoch 164/200\n",
      "53/53 [==============================] - 0s 87us/step - loss: 0.2384 - acc: 0.9245\n",
      "Epoch 165/200\n",
      "53/53 [==============================] - 0s 89us/step - loss: 0.2374 - acc: 0.9245\n",
      "Epoch 166/200\n",
      "53/53 [==============================] - 0s 92us/step - loss: 0.2372 - acc: 0.9245\n",
      "Epoch 167/200\n",
      "53/53 [==============================] - 0s 77us/step - loss: 0.2361 - acc: 0.9245\n",
      "Epoch 168/200\n",
      "53/53 [==============================] - 0s 101us/step - loss: 0.2353 - acc: 0.9245\n",
      "Epoch 169/200\n",
      "53/53 [==============================] - 0s 82us/step - loss: 0.2352 - acc: 0.9245\n",
      "Epoch 170/200\n",
      "53/53 [==============================] - 0s 91us/step - loss: 0.2343 - acc: 0.9245\n",
      "Epoch 171/200\n",
      "53/53 [==============================] - 0s 116us/step - loss: 0.2341 - acc: 0.9245\n",
      "Epoch 172/200\n",
      "53/53 [==============================] - 0s 134us/step - loss: 0.2332 - acc: 0.9245\n",
      "Epoch 173/200\n",
      "53/53 [==============================] - 0s 103us/step - loss: 0.2323 - acc: 0.9245\n",
      "Epoch 174/200\n",
      "53/53 [==============================] - 0s 106us/step - loss: 0.2317 - acc: 0.9245\n",
      "Epoch 175/200\n",
      "53/53 [==============================] - 0s 96us/step - loss: 0.2309 - acc: 0.9245\n",
      "Epoch 176/200\n",
      "53/53 [==============================] - 0s 94us/step - loss: 0.2310 - acc: 0.9245\n",
      "Epoch 177/200\n",
      "53/53 [==============================] - 0s 90us/step - loss: 0.2296 - acc: 0.9245\n",
      "Epoch 178/200\n",
      "53/53 [==============================] - 0s 87us/step - loss: 0.2289 - acc: 0.9245\n",
      "Epoch 179/200\n",
      "53/53 [==============================] - 0s 103us/step - loss: 0.2279 - acc: 0.9245\n",
      "Epoch 180/200\n",
      "53/53 [==============================] - 0s 80us/step - loss: 0.2271 - acc: 0.9245\n",
      "Epoch 181/200\n",
      "53/53 [==============================] - 0s 132us/step - loss: 0.2270 - acc: 0.9245\n",
      "Epoch 182/200\n",
      "53/53 [==============================] - 0s 131us/step - loss: 0.2257 - acc: 0.9245\n",
      "Epoch 183/200\n",
      "53/53 [==============================] - 0s 115us/step - loss: 0.2251 - acc: 0.9245\n",
      "Epoch 184/200\n",
      "53/53 [==============================] - 0s 82us/step - loss: 0.2242 - acc: 0.9245\n",
      "Epoch 185/200\n",
      "53/53 [==============================] - 0s 77us/step - loss: 0.2237 - acc: 0.9245\n",
      "Epoch 186/200\n",
      "53/53 [==============================] - 0s 93us/step - loss: 0.2231 - acc: 0.9245\n",
      "Epoch 187/200\n",
      "53/53 [==============================] - 0s 89us/step - loss: 0.2224 - acc: 0.9245\n",
      "Epoch 188/200\n",
      "53/53 [==============================] - 0s 76us/step - loss: 0.2216 - acc: 0.9245\n",
      "Epoch 189/200\n",
      "53/53 [==============================] - 0s 75us/step - loss: 0.2210 - acc: 0.9245\n",
      "Epoch 190/200\n",
      "53/53 [==============================] - 0s 89us/step - loss: 0.2204 - acc: 0.9245\n",
      "Epoch 191/200\n",
      "53/53 [==============================] - 0s 81us/step - loss: 0.2195 - acc: 0.9245\n",
      "Epoch 192/200\n",
      "53/53 [==============================] - 0s 87us/step - loss: 0.2188 - acc: 0.9245\n",
      "Epoch 193/200\n",
      "53/53 [==============================] - 0s 72us/step - loss: 0.2182 - acc: 0.9245\n",
      "Epoch 194/200\n",
      "53/53 [==============================] - 0s 131us/step - loss: 0.2174 - acc: 0.9245\n",
      "Epoch 195/200\n",
      "53/53 [==============================] - 0s 79us/step - loss: 0.2169 - acc: 0.9245\n",
      "Epoch 196/200\n",
      "53/53 [==============================] - 0s 92us/step - loss: 0.2163 - acc: 0.9245\n",
      "Epoch 197/200\n",
      "53/53 [==============================] - 0s 73us/step - loss: 0.2155 - acc: 0.9245\n",
      "Epoch 198/200\n",
      "53/53 [==============================] - 0s 97us/step - loss: 0.2148 - acc: 0.9245\n",
      "Epoch 199/200\n",
      "53/53 [==============================] - 0s 81us/step - loss: 0.2141 - acc: 0.9245\n",
      "Epoch 200/200\n",
      "53/53 [==============================] - 0s 72us/step - loss: 0.2136 - acc: 0.9245\n",
      "27/27 [==============================] - 0s 1ms/step\n",
      "Epoch 1/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.6931 - acc: 0.5472\n",
      "Epoch 2/200\n",
      "53/53 [==============================] - 0s 82us/step - loss: 0.6929 - acc: 0.5472\n",
      "Epoch 3/200\n",
      "53/53 [==============================] - 0s 80us/step - loss: 0.6928 - acc: 0.5472\n",
      "Epoch 4/200\n",
      "53/53 [==============================] - 0s 83us/step - loss: 0.6926 - acc: 0.5472\n",
      "Epoch 5/200\n",
      "53/53 [==============================] - 0s 77us/step - loss: 0.6925 - acc: 0.5472\n",
      "Epoch 6/200\n",
      "53/53 [==============================] - 0s 77us/step - loss: 0.6923 - acc: 0.5472\n",
      "Epoch 7/200\n",
      "53/53 [==============================] - 0s 78us/step - loss: 0.6922 - acc: 0.5472\n",
      "Epoch 8/200\n",
      "53/53 [==============================] - 0s 108us/step - loss: 0.6920 - acc: 0.5472\n",
      "Epoch 9/200\n",
      "53/53 [==============================] - 0s 89us/step - loss: 0.6918 - acc: 0.5472\n",
      "Epoch 10/200\n",
      "53/53 [==============================] - 0s 92us/step - loss: 0.6916 - acc: 0.5472\n",
      "Epoch 11/200\n",
      "53/53 [==============================] - 0s 128us/step - loss: 0.6913 - acc: 0.5472\n",
      "Epoch 12/200\n",
      "53/53 [==============================] - 0s 86us/step - loss: 0.6910 - acc: 0.5472\n",
      "Epoch 13/200\n",
      "53/53 [==============================] - 0s 78us/step - loss: 0.6907 - acc: 0.5472\n",
      "Epoch 14/200\n",
      "53/53 [==============================] - 0s 82us/step - loss: 0.6903 - acc: 0.5472\n",
      "Epoch 15/200\n",
      "53/53 [==============================] - 0s 83us/step - loss: 0.6900 - acc: 0.5472\n",
      "Epoch 16/200\n",
      "53/53 [==============================] - 0s 83us/step - loss: 0.6894 - acc: 0.5472\n",
      "Epoch 17/200\n",
      "53/53 [==============================] - 0s 92us/step - loss: 0.6890 - acc: 0.5472\n",
      "Epoch 18/200\n",
      "53/53 [==============================] - 0s 88us/step - loss: 0.6884 - acc: 0.5472\n",
      "Epoch 19/200\n",
      "53/53 [==============================] - 0s 82us/step - loss: 0.6878 - acc: 0.5472\n",
      "Epoch 20/200\n",
      "53/53 [==============================] - 0s 93us/step - loss: 0.6871 - acc: 0.5472\n",
      "Epoch 21/200\n",
      "53/53 [==============================] - 0s 95us/step - loss: 0.6863 - acc: 0.5472\n",
      "Epoch 22/200\n",
      "53/53 [==============================] - 0s 95us/step - loss: 0.6856 - acc: 0.5472\n",
      "Epoch 23/200\n",
      "53/53 [==============================] - 0s 118us/step - loss: 0.6845 - acc: 0.5472\n",
      "Epoch 24/200\n",
      "53/53 [==============================] - 0s 95us/step - loss: 0.6838 - acc: 0.5472\n",
      "Epoch 25/200\n",
      "53/53 [==============================] - 0s 88us/step - loss: 0.6823 - acc: 0.5472\n",
      "Epoch 26/200\n",
      "53/53 [==============================] - 0s 85us/step - loss: 0.6812 - acc: 0.5660\n",
      "Epoch 27/200\n",
      "53/53 [==============================] - 0s 81us/step - loss: 0.6799 - acc: 0.5660\n",
      "Epoch 28/200\n",
      "53/53 [==============================] - 0s 73us/step - loss: 0.6783 - acc: 0.5660\n",
      "Epoch 29/200\n",
      "53/53 [==============================] - 0s 72us/step - loss: 0.6769 - acc: 0.5660\n",
      "Epoch 30/200\n",
      "53/53 [==============================] - 0s 88us/step - loss: 0.6751 - acc: 0.5660\n",
      "Epoch 31/200\n",
      "53/53 [==============================] - 0s 80us/step - loss: 0.6732 - acc: 0.5849\n",
      "Epoch 32/200\n",
      "53/53 [==============================] - 0s 80us/step - loss: 0.6710 - acc: 0.5849\n",
      "Epoch 33/200\n",
      "53/53 [==============================] - 0s 76us/step - loss: 0.6688 - acc: 0.6038\n",
      "Epoch 34/200\n",
      "53/53 [==============================] - 0s 76us/step - loss: 0.6664 - acc: 0.6038\n",
      "Epoch 35/200\n",
      "53/53 [==============================] - 0s 82us/step - loss: 0.6636 - acc: 0.6226\n",
      "Epoch 36/200\n",
      "53/53 [==============================] - 0s 87us/step - loss: 0.6609 - acc: 0.6415\n",
      "Epoch 37/200\n",
      "53/53 [==============================] - 0s 78us/step - loss: 0.6577 - acc: 0.6415\n",
      "Epoch 38/200\n",
      "53/53 [==============================] - 0s 81us/step - loss: 0.6546 - acc: 0.6415\n",
      "Epoch 39/200\n",
      "53/53 [==============================] - 0s 86us/step - loss: 0.6512 - acc: 0.6415\n",
      "Epoch 40/200\n",
      "53/53 [==============================] - 0s 93us/step - loss: 0.6473 - acc: 0.6792\n",
      "Epoch 41/200\n",
      "53/53 [==============================] - 0s 91us/step - loss: 0.6433 - acc: 0.6981\n",
      "Epoch 42/200\n",
      "53/53 [==============================] - 0s 81us/step - loss: 0.6394 - acc: 0.6792\n",
      "Epoch 43/200\n",
      "53/53 [==============================] - 0s 86us/step - loss: 0.6352 - acc: 0.7170\n",
      "Epoch 44/200\n",
      "53/53 [==============================] - 0s 77us/step - loss: 0.6310 - acc: 0.7358\n",
      "Epoch 45/200\n",
      "53/53 [==============================] - 0s 69us/step - loss: 0.6263 - acc: 0.7358\n",
      "Epoch 46/200\n",
      "53/53 [==============================] - 0s 86us/step - loss: 0.6212 - acc: 0.7358\n",
      "Epoch 47/200\n",
      "53/53 [==============================] - 0s 98us/step - loss: 0.6164 - acc: 0.7736\n",
      "Epoch 48/200\n",
      "53/53 [==============================] - 0s 110us/step - loss: 0.6114 - acc: 0.7925\n",
      "Epoch 49/200\n",
      "53/53 [==============================] - 0s 104us/step - loss: 0.6057 - acc: 0.7925\n",
      "Epoch 50/200\n",
      "53/53 [==============================] - 0s 93us/step - loss: 0.6003 - acc: 0.8113\n",
      "Epoch 51/200\n",
      "53/53 [==============================] - 0s 85us/step - loss: 0.5942 - acc: 0.8113\n",
      "Epoch 52/200\n",
      "53/53 [==============================] - 0s 86us/step - loss: 0.5884 - acc: 0.8113\n",
      "Epoch 53/200\n",
      "53/53 [==============================] - 0s 78us/step - loss: 0.5828 - acc: 0.8113\n",
      "Epoch 54/200\n",
      "53/53 [==============================] - 0s 113us/step - loss: 0.5761 - acc: 0.8302\n",
      "Epoch 55/200\n",
      "53/53 [==============================] - 0s 89us/step - loss: 0.5698 - acc: 0.8302\n",
      "Epoch 56/200\n",
      "53/53 [==============================] - 0s 86us/step - loss: 0.5635 - acc: 0.8302\n",
      "Epoch 57/200\n",
      "53/53 [==============================] - 0s 100us/step - loss: 0.5565 - acc: 0.8302\n",
      "Epoch 58/200\n",
      "53/53 [==============================] - 0s 103us/step - loss: 0.5503 - acc: 0.8302\n",
      "Epoch 59/200\n",
      "53/53 [==============================] - 0s 96us/step - loss: 0.5436 - acc: 0.8302\n",
      "Epoch 60/200\n",
      "53/53 [==============================] - 0s 102us/step - loss: 0.5363 - acc: 0.8679\n",
      "Epoch 61/200\n",
      "53/53 [==============================] - 0s 86us/step - loss: 0.5294 - acc: 0.8679\n",
      "Epoch 62/200\n",
      "53/53 [==============================] - 0s 78us/step - loss: 0.5230 - acc: 0.8679\n",
      "Epoch 63/200\n",
      "53/53 [==============================] - 0s 84us/step - loss: 0.5168 - acc: 0.8679\n",
      "Epoch 64/200\n",
      "53/53 [==============================] - 0s 80us/step - loss: 0.5096 - acc: 0.8679\n",
      "Epoch 65/200\n",
      "53/53 [==============================] - 0s 100us/step - loss: 0.5033 - acc: 0.8679\n",
      "Epoch 66/200\n",
      "53/53 [==============================] - 0s 75us/step - loss: 0.4961 - acc: 0.8679\n",
      "Epoch 67/200\n",
      "53/53 [==============================] - 0s 88us/step - loss: 0.4896 - acc: 0.8679\n",
      "Epoch 68/200\n",
      "53/53 [==============================] - 0s 94us/step - loss: 0.4836 - acc: 0.8679\n",
      "Epoch 69/200\n",
      "53/53 [==============================] - 0s 91us/step - loss: 0.4762 - acc: 0.8679\n",
      "Epoch 70/200\n",
      "53/53 [==============================] - 0s 89us/step - loss: 0.4705 - acc: 0.8679\n",
      "Epoch 71/200\n",
      "53/53 [==============================] - 0s 106us/step - loss: 0.4640 - acc: 0.8679\n",
      "Epoch 72/200\n",
      "53/53 [==============================] - 0s 95us/step - loss: 0.4587 - acc: 0.8679\n",
      "Epoch 73/200\n",
      "53/53 [==============================] - 0s 77us/step - loss: 0.4522 - acc: 0.8679\n",
      "Epoch 74/200\n",
      "53/53 [==============================] - 0s 80us/step - loss: 0.4460 - acc: 0.8679\n",
      "Epoch 75/200\n",
      "53/53 [==============================] - 0s 79us/step - loss: 0.4403 - acc: 0.8679\n",
      "Epoch 76/200\n",
      "53/53 [==============================] - 0s 76us/step - loss: 0.4350 - acc: 0.8679\n",
      "Epoch 77/200\n",
      "53/53 [==============================] - 0s 84us/step - loss: 0.4293 - acc: 0.8679\n",
      "Epoch 78/200\n",
      "53/53 [==============================] - 0s 72us/step - loss: 0.4241 - acc: 0.8679\n",
      "Epoch 79/200\n",
      "53/53 [==============================] - 0s 97us/step - loss: 0.4187 - acc: 0.8679\n",
      "Epoch 80/200\n",
      "53/53 [==============================] - 0s 83us/step - loss: 0.4137 - acc: 0.8679\n",
      "Epoch 81/200\n",
      "53/53 [==============================] - 0s 78us/step - loss: 0.4082 - acc: 0.8679\n",
      "Epoch 82/200\n",
      "53/53 [==============================] - 0s 93us/step - loss: 0.4037 - acc: 0.8679\n",
      "Epoch 83/200\n",
      "53/53 [==============================] - 0s 111us/step - loss: 0.3993 - acc: 0.8679\n",
      "Epoch 84/200\n",
      "53/53 [==============================] - 0s 113us/step - loss: 0.3947 - acc: 0.8491\n",
      "Epoch 85/200\n",
      "53/53 [==============================] - 0s 87us/step - loss: 0.3903 - acc: 0.8491\n",
      "Epoch 86/200\n",
      "53/53 [==============================] - 0s 86us/step - loss: 0.3866 - acc: 0.8491\n",
      "Epoch 87/200\n",
      "53/53 [==============================] - 0s 84us/step - loss: 0.3822 - acc: 0.8491\n",
      "Epoch 88/200\n",
      "53/53 [==============================] - 0s 90us/step - loss: 0.3776 - acc: 0.8491\n",
      "Epoch 89/200\n",
      "53/53 [==============================] - 0s 73us/step - loss: 0.3741 - acc: 0.8491\n",
      "Epoch 90/200\n",
      "53/53 [==============================] - 0s 83us/step - loss: 0.3704 - acc: 0.8679\n",
      "Epoch 91/200\n",
      "53/53 [==============================] - 0s 87us/step - loss: 0.3667 - acc: 0.8679\n",
      "Epoch 92/200\n",
      "53/53 [==============================] - 0s 105us/step - loss: 0.3631 - acc: 0.8679\n",
      "Epoch 93/200\n",
      "53/53 [==============================] - 0s 84us/step - loss: 0.3603 - acc: 0.8679\n",
      "Epoch 94/200\n",
      "53/53 [==============================] - 0s 83us/step - loss: 0.3582 - acc: 0.8491\n",
      "Epoch 95/200\n",
      "53/53 [==============================] - 0s 76us/step - loss: 0.3536 - acc: 0.8491\n",
      "Epoch 96/200\n",
      "53/53 [==============================] - 0s 83us/step - loss: 0.3511 - acc: 0.8679\n",
      "Epoch 97/200\n",
      "53/53 [==============================] - 0s 80us/step - loss: 0.3486 - acc: 0.8679\n",
      "Epoch 98/200\n",
      "53/53 [==============================] - 0s 83us/step - loss: 0.3453 - acc: 0.8679\n",
      "Epoch 99/200\n",
      "53/53 [==============================] - 0s 95us/step - loss: 0.3428 - acc: 0.8868\n",
      "Epoch 100/200\n",
      "53/53 [==============================] - 0s 106us/step - loss: 0.3396 - acc: 0.8868\n",
      "Epoch 101/200\n",
      "53/53 [==============================] - 0s 84us/step - loss: 0.3372 - acc: 0.8868\n",
      "Epoch 102/200\n",
      "53/53 [==============================] - 0s 92us/step - loss: 0.3345 - acc: 0.8868\n",
      "Epoch 103/200\n",
      "53/53 [==============================] - 0s 116us/step - loss: 0.3322 - acc: 0.8868\n",
      "Epoch 104/200\n",
      "53/53 [==============================] - 0s 90us/step - loss: 0.3293 - acc: 0.8868\n",
      "Epoch 105/200\n",
      "53/53 [==============================] - 0s 91us/step - loss: 0.3268 - acc: 0.8868\n",
      "Epoch 106/200\n",
      "53/53 [==============================] - 0s 94us/step - loss: 0.3246 - acc: 0.8868\n",
      "Epoch 107/200\n",
      "53/53 [==============================] - 0s 82us/step - loss: 0.3224 - acc: 0.8868\n",
      "Epoch 108/200\n",
      "53/53 [==============================] - 0s 79us/step - loss: 0.3203 - acc: 0.8868\n",
      "Epoch 109/200\n",
      "53/53 [==============================] - 0s 83us/step - loss: 0.3185 - acc: 0.8868\n",
      "Epoch 110/200\n",
      "53/53 [==============================] - 0s 77us/step - loss: 0.3159 - acc: 0.8868\n",
      "Epoch 111/200\n",
      "53/53 [==============================] - 0s 74us/step - loss: 0.3138 - acc: 0.8868\n",
      "Epoch 112/200\n",
      "53/53 [==============================] - 0s 95us/step - loss: 0.3118 - acc: 0.8868\n",
      "Epoch 113/200\n",
      "53/53 [==============================] - 0s 122us/step - loss: 0.3095 - acc: 0.8868\n",
      "Epoch 114/200\n",
      "53/53 [==============================] - 0s 77us/step - loss: 0.3078 - acc: 0.8868\n",
      "Epoch 115/200\n",
      "53/53 [==============================] - 0s 82us/step - loss: 0.3056 - acc: 0.8868\n",
      "Epoch 116/200\n",
      "53/53 [==============================] - 0s 90us/step - loss: 0.3036 - acc: 0.8868\n",
      "Epoch 117/200\n",
      "53/53 [==============================] - 0s 98us/step - loss: 0.3018 - acc: 0.8868\n",
      "Epoch 118/200\n",
      "53/53 [==============================] - 0s 123us/step - loss: 0.3003 - acc: 0.8868\n",
      "Epoch 119/200\n",
      "53/53 [==============================] - 0s 89us/step - loss: 0.2985 - acc: 0.8868\n",
      "Epoch 120/200\n",
      "53/53 [==============================] - 0s 87us/step - loss: 0.2964 - acc: 0.8868\n",
      "Epoch 121/200\n",
      "53/53 [==============================] - 0s 106us/step - loss: 0.2947 - acc: 0.8868\n",
      "Epoch 122/200\n",
      "53/53 [==============================] - 0s 93us/step - loss: 0.2933 - acc: 0.8868\n",
      "Epoch 123/200\n",
      "53/53 [==============================] - 0s 103us/step - loss: 0.2919 - acc: 0.8868\n",
      "Epoch 124/200\n",
      "53/53 [==============================] - 0s 90us/step - loss: 0.2912 - acc: 0.8868\n",
      "Epoch 125/200\n",
      "53/53 [==============================] - 0s 77us/step - loss: 0.2885 - acc: 0.8868\n",
      "Epoch 126/200\n",
      "53/53 [==============================] - 0s 75us/step - loss: 0.2869 - acc: 0.8868\n",
      "Epoch 127/200\n",
      "53/53 [==============================] - 0s 102us/step - loss: 0.2857 - acc: 0.9057\n",
      "Epoch 128/200\n",
      "53/53 [==============================] - 0s 89us/step - loss: 0.2838 - acc: 0.9057\n",
      "Epoch 129/200\n",
      "53/53 [==============================] - 0s 86us/step - loss: 0.2821 - acc: 0.9057\n",
      "Epoch 130/200\n",
      "53/53 [==============================] - 0s 81us/step - loss: 0.2819 - acc: 0.8868\n",
      "Epoch 131/200\n",
      "53/53 [==============================] - 0s 82us/step - loss: 0.2796 - acc: 0.8868\n",
      "Epoch 132/200\n",
      "53/53 [==============================] - 0s 87us/step - loss: 0.2784 - acc: 0.8868\n",
      "Epoch 133/200\n",
      "53/53 [==============================] - 0s 88us/step - loss: 0.2767 - acc: 0.8868\n",
      "Epoch 134/200\n",
      "53/53 [==============================] - 0s 80us/step - loss: 0.2755 - acc: 0.8868\n",
      "Epoch 135/200\n",
      "53/53 [==============================] - 0s 113us/step - loss: 0.2742 - acc: 0.8868\n",
      "Epoch 136/200\n",
      "53/53 [==============================] - 0s 89us/step - loss: 0.2726 - acc: 0.9245\n",
      "Epoch 137/200\n",
      "53/53 [==============================] - 0s 138us/step - loss: 0.2713 - acc: 0.9245\n",
      "Epoch 138/200\n",
      "53/53 [==============================] - 0s 99us/step - loss: 0.2702 - acc: 0.9245\n",
      "Epoch 139/200\n",
      "53/53 [==============================] - 0s 89us/step - loss: 0.2689 - acc: 0.9245\n",
      "Epoch 140/200\n",
      "53/53 [==============================] - 0s 117us/step - loss: 0.2678 - acc: 0.9245\n",
      "Epoch 141/200\n",
      "53/53 [==============================] - 0s 82us/step - loss: 0.2665 - acc: 0.9245\n",
      "Epoch 142/200\n",
      "53/53 [==============================] - 0s 91us/step - loss: 0.2656 - acc: 0.9245\n",
      "Epoch 143/200\n",
      "53/53 [==============================] - 0s 83us/step - loss: 0.2641 - acc: 0.9245\n",
      "Epoch 144/200\n",
      "53/53 [==============================] - 0s 88us/step - loss: 0.2629 - acc: 0.9245\n",
      "Epoch 145/200\n",
      "53/53 [==============================] - 0s 90us/step - loss: 0.2620 - acc: 0.9245\n",
      "Epoch 146/200\n",
      "53/53 [==============================] - 0s 93us/step - loss: 0.2605 - acc: 0.9245\n",
      "Epoch 147/200\n",
      "53/53 [==============================] - 0s 86us/step - loss: 0.2593 - acc: 0.9245\n",
      "Epoch 148/200\n",
      "53/53 [==============================] - 0s 76us/step - loss: 0.2584 - acc: 0.9245\n",
      "Epoch 149/200\n",
      "53/53 [==============================] - 0s 94us/step - loss: 0.2574 - acc: 0.9245\n",
      "Epoch 150/200\n",
      "53/53 [==============================] - 0s 93us/step - loss: 0.2563 - acc: 0.9245\n",
      "Epoch 151/200\n",
      "53/53 [==============================] - 0s 79us/step - loss: 0.2550 - acc: 0.9245\n",
      "Epoch 152/200\n",
      "53/53 [==============================] - 0s 74us/step - loss: 0.2539 - acc: 0.9245\n",
      "Epoch 153/200\n",
      "53/53 [==============================] - 0s 79us/step - loss: 0.2528 - acc: 0.9245\n",
      "Epoch 154/200\n",
      "53/53 [==============================] - 0s 82us/step - loss: 0.2520 - acc: 0.9245\n",
      "Epoch 155/200\n",
      "53/53 [==============================] - 0s 123us/step - loss: 0.2511 - acc: 0.9245\n",
      "Epoch 156/200\n",
      "53/53 [==============================] - 0s 140us/step - loss: 0.2499 - acc: 0.9245\n",
      "Epoch 157/200\n",
      "53/53 [==============================] - 0s 97us/step - loss: 0.2489 - acc: 0.9245\n",
      "Epoch 158/200\n",
      "53/53 [==============================] - 0s 107us/step - loss: 0.2485 - acc: 0.9245\n",
      "Epoch 159/200\n",
      "53/53 [==============================] - 0s 87us/step - loss: 0.2470 - acc: 0.9245\n",
      "Epoch 160/200\n",
      "53/53 [==============================] - 0s 141us/step - loss: 0.2461 - acc: 0.9245\n",
      "Epoch 161/200\n",
      "53/53 [==============================] - 0s 78us/step - loss: 0.2456 - acc: 0.9245\n",
      "Epoch 162/200\n",
      "53/53 [==============================] - 0s 80us/step - loss: 0.2449 - acc: 0.9245\n",
      "Epoch 163/200\n",
      "53/53 [==============================] - 0s 89us/step - loss: 0.2439 - acc: 0.9245\n",
      "Epoch 164/200\n",
      "53/53 [==============================] - 0s 83us/step - loss: 0.2437 - acc: 0.9245\n",
      "Epoch 165/200\n",
      "53/53 [==============================] - 0s 95us/step - loss: 0.2415 - acc: 0.9245\n",
      "Epoch 166/200\n",
      "53/53 [==============================] - 0s 81us/step - loss: 0.2407 - acc: 0.9245\n",
      "Epoch 167/200\n",
      "53/53 [==============================] - 0s 86us/step - loss: 0.2410 - acc: 0.9245\n",
      "Epoch 168/200\n",
      "53/53 [==============================] - 0s 116us/step - loss: 0.2400 - acc: 0.9245\n",
      "Epoch 169/200\n",
      "53/53 [==============================] - 0s 92us/step - loss: 0.2392 - acc: 0.9245\n",
      "Epoch 170/200\n",
      "53/53 [==============================] - 0s 106us/step - loss: 0.2384 - acc: 0.9245\n",
      "Epoch 171/200\n",
      "53/53 [==============================] - 0s 127us/step - loss: 0.2375 - acc: 0.9245\n",
      "Epoch 172/200\n",
      "53/53 [==============================] - 0s 119us/step - loss: 0.2363 - acc: 0.9245\n",
      "Epoch 173/200\n",
      "53/53 [==============================] - 0s 83us/step - loss: 0.2353 - acc: 0.9245\n",
      "Epoch 174/200\n",
      "53/53 [==============================] - 0s 82us/step - loss: 0.2345 - acc: 0.9057\n",
      "Epoch 175/200\n",
      "53/53 [==============================] - 0s 85us/step - loss: 0.2341 - acc: 0.9057\n",
      "Epoch 176/200\n",
      "53/53 [==============================] - 0s 87us/step - loss: 0.2336 - acc: 0.9057\n",
      "Epoch 177/200\n",
      "53/53 [==============================] - 0s 88us/step - loss: 0.2330 - acc: 0.9057\n",
      "Epoch 178/200\n",
      "53/53 [==============================] - 0s 92us/step - loss: 0.2322 - acc: 0.9057\n",
      "Epoch 179/200\n",
      "53/53 [==============================] - 0s 83us/step - loss: 0.2312 - acc: 0.9057\n",
      "Epoch 180/200\n",
      "53/53 [==============================] - 0s 83us/step - loss: 0.2307 - acc: 0.9057\n",
      "Epoch 181/200\n",
      "53/53 [==============================] - 0s 106us/step - loss: 0.2296 - acc: 0.9057\n",
      "Epoch 182/200\n",
      "53/53 [==============================] - 0s 99us/step - loss: 0.2288 - acc: 0.9057\n",
      "Epoch 183/200\n",
      "53/53 [==============================] - 0s 141us/step - loss: 0.2283 - acc: 0.9057\n",
      "Epoch 184/200\n",
      "53/53 [==============================] - 0s 84us/step - loss: 0.2277 - acc: 0.9057\n",
      "Epoch 185/200\n",
      "53/53 [==============================] - 0s 80us/step - loss: 0.2274 - acc: 0.9057\n",
      "Epoch 186/200\n",
      "53/53 [==============================] - 0s 78us/step - loss: 0.2271 - acc: 0.9057\n",
      "Epoch 187/200\n",
      "53/53 [==============================] - 0s 89us/step - loss: 0.2259 - acc: 0.9057\n",
      "Epoch 188/200\n",
      "53/53 [==============================] - 0s 85us/step - loss: 0.2253 - acc: 0.9057\n",
      "Epoch 189/200\n",
      "53/53 [==============================] - 0s 111us/step - loss: 0.2245 - acc: 0.9057\n",
      "Epoch 190/200\n",
      "53/53 [==============================] - 0s 94us/step - loss: 0.2239 - acc: 0.9057\n",
      "Epoch 191/200\n",
      "53/53 [==============================] - 0s 75us/step - loss: 0.2248 - acc: 0.9057\n",
      "Epoch 192/200\n",
      "53/53 [==============================] - 0s 86us/step - loss: 0.2226 - acc: 0.9057\n",
      "Epoch 193/200\n",
      "53/53 [==============================] - 0s 84us/step - loss: 0.2218 - acc: 0.9057\n",
      "Epoch 194/200\n",
      "53/53 [==============================] - 0s 97us/step - loss: 0.2223 - acc: 0.9057\n",
      "Epoch 195/200\n",
      "53/53 [==============================] - 0s 92us/step - loss: 0.2206 - acc: 0.9057\n",
      "Epoch 196/200\n",
      "53/53 [==============================] - 0s 167us/step - loss: 0.2209 - acc: 0.9057\n",
      "Epoch 197/200\n",
      "53/53 [==============================] - 0s 111us/step - loss: 0.2196 - acc: 0.9057\n",
      "Epoch 198/200\n",
      "53/53 [==============================] - 0s 137us/step - loss: 0.2192 - acc: 0.9057\n",
      "Epoch 199/200\n",
      "53/53 [==============================] - 0s 126us/step - loss: 0.2185 - acc: 0.9057\n",
      "Epoch 200/200\n",
      "53/53 [==============================] - 0s 125us/step - loss: 0.2179 - acc: 0.9057\n",
      "27/27 [==============================] - 0s 2ms/step\n",
      "Epoch 1/200\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.6931 - acc: 0.5741\n",
      "Epoch 2/200\n",
      "54/54 [==============================] - 0s 81us/step - loss: 0.6927 - acc: 0.6296\n",
      "Epoch 3/200\n",
      "54/54 [==============================] - 0s 83us/step - loss: 0.6924 - acc: 0.6296\n",
      "Epoch 4/200\n",
      "54/54 [==============================] - 0s 78us/step - loss: 0.6920 - acc: 0.6296\n",
      "Epoch 5/200\n",
      "54/54 [==============================] - 0s 76us/step - loss: 0.6915 - acc: 0.6296\n",
      "Epoch 6/200\n",
      "54/54 [==============================] - 0s 71us/step - loss: 0.6911 - acc: 0.6296\n",
      "Epoch 7/200\n",
      "54/54 [==============================] - 0s 80us/step - loss: 0.6906 - acc: 0.6296\n",
      "Epoch 8/200\n",
      "54/54 [==============================] - 0s 94us/step - loss: 0.6900 - acc: 0.6296\n",
      "Epoch 9/200\n",
      "54/54 [==============================] - 0s 85us/step - loss: 0.6896 - acc: 0.6296\n",
      "Epoch 10/200\n",
      "54/54 [==============================] - 0s 77us/step - loss: 0.6889 - acc: 0.6296\n",
      "Epoch 11/200\n",
      "54/54 [==============================] - 0s 78us/step - loss: 0.6883 - acc: 0.6296\n",
      "Epoch 12/200\n",
      "54/54 [==============================] - 0s 89us/step - loss: 0.6875 - acc: 0.6296\n",
      "Epoch 13/200\n",
      "54/54 [==============================] - 0s 88us/step - loss: 0.6867 - acc: 0.6296\n",
      "Epoch 14/200\n",
      "54/54 [==============================] - 0s 75us/step - loss: 0.6859 - acc: 0.6296\n",
      "Epoch 15/200\n",
      "54/54 [==============================] - 0s 85us/step - loss: 0.6849 - acc: 0.6296\n",
      "Epoch 16/200\n",
      "54/54 [==============================] - 0s 83us/step - loss: 0.6837 - acc: 0.6296\n",
      "Epoch 17/200\n",
      "54/54 [==============================] - 0s 73us/step - loss: 0.6828 - acc: 0.6296\n",
      "Epoch 18/200\n",
      "54/54 [==============================] - 0s 84us/step - loss: 0.6813 - acc: 0.6296\n",
      "Epoch 19/200\n",
      "54/54 [==============================] - 0s 80us/step - loss: 0.6799 - acc: 0.6296\n",
      "Epoch 20/200\n",
      "54/54 [==============================] - 0s 92us/step - loss: 0.6784 - acc: 0.6296\n",
      "Epoch 21/200\n",
      "54/54 [==============================] - 0s 72us/step - loss: 0.6767 - acc: 0.6296\n",
      "Epoch 22/200\n",
      "54/54 [==============================] - 0s 77us/step - loss: 0.6749 - acc: 0.6296\n",
      "Epoch 23/200\n",
      "54/54 [==============================] - 0s 93us/step - loss: 0.6728 - acc: 0.6296\n",
      "Epoch 24/200\n",
      "54/54 [==============================] - 0s 94us/step - loss: 0.6706 - acc: 0.6296\n",
      "Epoch 25/200\n",
      "54/54 [==============================] - 0s 75us/step - loss: 0.6684 - acc: 0.6296\n",
      "Epoch 26/200\n",
      "54/54 [==============================] - 0s 73us/step - loss: 0.6657 - acc: 0.6296\n",
      "Epoch 27/200\n",
      "54/54 [==============================] - 0s 76us/step - loss: 0.6630 - acc: 0.6296\n",
      "Epoch 28/200\n",
      "54/54 [==============================] - 0s 70us/step - loss: 0.6602 - acc: 0.6296\n",
      "Epoch 29/200\n",
      "54/54 [==============================] - 0s 91us/step - loss: 0.6566 - acc: 0.6296\n",
      "Epoch 30/200\n",
      "54/54 [==============================] - 0s 69us/step - loss: 0.6544 - acc: 0.6296\n",
      "Epoch 31/200\n",
      "54/54 [==============================] - 0s 70us/step - loss: 0.6512 - acc: 0.6296\n",
      "Epoch 32/200\n",
      "54/54 [==============================] - 0s 77us/step - loss: 0.6479 - acc: 0.6296\n",
      "Epoch 33/200\n",
      "54/54 [==============================] - 0s 91us/step - loss: 0.6447 - acc: 0.6296\n",
      "Epoch 34/200\n",
      "54/54 [==============================] - 0s 89us/step - loss: 0.6416 - acc: 0.6296\n",
      "Epoch 35/200\n",
      "54/54 [==============================] - 0s 115us/step - loss: 0.6389 - acc: 0.6296\n",
      "Epoch 36/200\n",
      "54/54 [==============================] - 0s 90us/step - loss: 0.6350 - acc: 0.6296\n",
      "Epoch 37/200\n",
      "54/54 [==============================] - 0s 96us/step - loss: 0.6318 - acc: 0.6296\n",
      "Epoch 38/200\n",
      "54/54 [==============================] - 0s 90us/step - loss: 0.6288 - acc: 0.6296\n",
      "Epoch 39/200\n",
      "54/54 [==============================] - 0s 100us/step - loss: 0.6253 - acc: 0.6296\n",
      "Epoch 40/200\n",
      "54/54 [==============================] - 0s 74us/step - loss: 0.6225 - acc: 0.6296\n",
      "Epoch 41/200\n",
      "54/54 [==============================] - 0s 85us/step - loss: 0.6195 - acc: 0.6296\n",
      "Epoch 42/200\n",
      "54/54 [==============================] - 0s 95us/step - loss: 0.6164 - acc: 0.6296\n",
      "Epoch 43/200\n",
      "54/54 [==============================] - 0s 82us/step - loss: 0.6133 - acc: 0.6296\n",
      "Epoch 44/200\n",
      "54/54 [==============================] - 0s 64us/step - loss: 0.6099 - acc: 0.6296\n",
      "Epoch 45/200\n",
      "54/54 [==============================] - 0s 67us/step - loss: 0.6069 - acc: 0.6296\n",
      "Epoch 46/200\n",
      "54/54 [==============================] - 0s 90us/step - loss: 0.6036 - acc: 0.6296\n",
      "Epoch 47/200\n",
      "54/54 [==============================] - 0s 83us/step - loss: 0.6009 - acc: 0.6296\n",
      "Epoch 48/200\n",
      "54/54 [==============================] - 0s 87us/step - loss: 0.5977 - acc: 0.6296\n",
      "Epoch 49/200\n",
      "54/54 [==============================] - 0s 81us/step - loss: 0.5944 - acc: 0.6296\n",
      "Epoch 50/200\n",
      "54/54 [==============================] - 0s 78us/step - loss: 0.5912 - acc: 0.6296\n",
      "Epoch 51/200\n",
      "54/54 [==============================] - 0s 80us/step - loss: 0.5881 - acc: 0.6296\n",
      "Epoch 52/200\n",
      "54/54 [==============================] - 0s 103us/step - loss: 0.5849 - acc: 0.6296\n",
      "Epoch 53/200\n",
      "54/54 [==============================] - 0s 93us/step - loss: 0.5813 - acc: 0.6296\n",
      "Epoch 54/200\n",
      "54/54 [==============================] - 0s 90us/step - loss: 0.5783 - acc: 0.6296\n",
      "Epoch 55/200\n",
      "54/54 [==============================] - 0s 91us/step - loss: 0.5745 - acc: 0.6296\n",
      "Epoch 56/200\n",
      "54/54 [==============================] - 0s 90us/step - loss: 0.5708 - acc: 0.6296\n",
      "Epoch 57/200\n",
      "54/54 [==============================] - 0s 74us/step - loss: 0.5671 - acc: 0.6296\n",
      "Epoch 58/200\n",
      "54/54 [==============================] - 0s 76us/step - loss: 0.5633 - acc: 0.6296\n",
      "Epoch 59/200\n",
      "54/54 [==============================] - 0s 91us/step - loss: 0.5595 - acc: 0.6481\n",
      "Epoch 60/200\n",
      "54/54 [==============================] - 0s 102us/step - loss: 0.5554 - acc: 0.6481\n",
      "Epoch 61/200\n",
      "54/54 [==============================] - 0s 88us/step - loss: 0.5510 - acc: 0.6481\n",
      "Epoch 62/200\n",
      "54/54 [==============================] - 0s 77us/step - loss: 0.5473 - acc: 0.6481\n",
      "Epoch 63/200\n",
      "54/54 [==============================] - 0s 101us/step - loss: 0.5426 - acc: 0.6481\n",
      "Epoch 64/200\n",
      "54/54 [==============================] - 0s 77us/step - loss: 0.5385 - acc: 0.6667\n",
      "Epoch 65/200\n",
      "54/54 [==============================] - 0s 83us/step - loss: 0.5343 - acc: 0.6852\n",
      "Epoch 66/200\n",
      "54/54 [==============================] - 0s 97us/step - loss: 0.5292 - acc: 0.6852\n",
      "Epoch 67/200\n",
      "54/54 [==============================] - 0s 97us/step - loss: 0.5251 - acc: 0.6852\n",
      "Epoch 68/200\n",
      "54/54 [==============================] - 0s 96us/step - loss: 0.5202 - acc: 0.6852\n",
      "Epoch 69/200\n",
      "54/54 [==============================] - 0s 89us/step - loss: 0.5152 - acc: 0.7222\n",
      "Epoch 70/200\n",
      "54/54 [==============================] - 0s 103us/step - loss: 0.5108 - acc: 0.7407\n",
      "Epoch 71/200\n",
      "54/54 [==============================] - 0s 86us/step - loss: 0.5063 - acc: 0.7222\n",
      "Epoch 72/200\n",
      "54/54 [==============================] - 0s 85us/step - loss: 0.5013 - acc: 0.7222\n",
      "Epoch 73/200\n",
      "54/54 [==============================] - 0s 79us/step - loss: 0.4968 - acc: 0.7222\n",
      "Epoch 74/200\n",
      "54/54 [==============================] - 0s 93us/step - loss: 0.4919 - acc: 0.7778\n",
      "Epoch 75/200\n",
      "54/54 [==============================] - 0s 80us/step - loss: 0.4872 - acc: 0.7778\n",
      "Epoch 76/200\n",
      "54/54 [==============================] - 0s 85us/step - loss: 0.4821 - acc: 0.7778\n",
      "Epoch 77/200\n",
      "54/54 [==============================] - 0s 80us/step - loss: 0.4766 - acc: 0.7778\n",
      "Epoch 78/200\n",
      "54/54 [==============================] - 0s 77us/step - loss: 0.4727 - acc: 0.7963\n",
      "Epoch 79/200\n",
      "54/54 [==============================] - 0s 102us/step - loss: 0.4679 - acc: 0.7963\n",
      "Epoch 80/200\n",
      "54/54 [==============================] - 0s 80us/step - loss: 0.4626 - acc: 0.8333\n",
      "Epoch 81/200\n",
      "54/54 [==============================] - 0s 79us/step - loss: 0.4585 - acc: 0.8333\n",
      "Epoch 82/200\n",
      "54/54 [==============================] - 0s 87us/step - loss: 0.4535 - acc: 0.8333\n",
      "Epoch 83/200\n",
      "54/54 [==============================] - 0s 88us/step - loss: 0.4487 - acc: 0.8519\n",
      "Epoch 84/200\n",
      "54/54 [==============================] - 0s 86us/step - loss: 0.4444 - acc: 0.8519\n",
      "Epoch 85/200\n",
      "54/54 [==============================] - 0s 80us/step - loss: 0.4401 - acc: 0.8519\n",
      "Epoch 86/200\n",
      "54/54 [==============================] - 0s 91us/step - loss: 0.4360 - acc: 0.8519\n",
      "Epoch 87/200\n",
      "54/54 [==============================] - 0s 93us/step - loss: 0.4317 - acc: 0.8519\n",
      "Epoch 88/200\n",
      "54/54 [==============================] - 0s 89us/step - loss: 0.4274 - acc: 0.8519\n",
      "Epoch 89/200\n",
      "54/54 [==============================] - 0s 96us/step - loss: 0.4232 - acc: 0.8519\n",
      "Epoch 90/200\n",
      "54/54 [==============================] - 0s 89us/step - loss: 0.4189 - acc: 0.8519\n",
      "Epoch 91/200\n",
      "54/54 [==============================] - 0s 76us/step - loss: 0.4153 - acc: 0.8519\n",
      "Epoch 92/200\n",
      "54/54 [==============================] - 0s 92us/step - loss: 0.4107 - acc: 0.8519\n",
      "Epoch 93/200\n",
      "54/54 [==============================] - 0s 115us/step - loss: 0.4076 - acc: 0.8519\n",
      "Epoch 94/200\n",
      "54/54 [==============================] - 0s 85us/step - loss: 0.4039 - acc: 0.8519\n",
      "Epoch 95/200\n",
      "54/54 [==============================] - 0s 104us/step - loss: 0.4007 - acc: 0.8519\n",
      "Epoch 96/200\n",
      "54/54 [==============================] - 0s 115us/step - loss: 0.3969 - acc: 0.8519\n",
      "Epoch 97/200\n",
      "54/54 [==============================] - 0s 92us/step - loss: 0.3938 - acc: 0.8333\n",
      "Epoch 98/200\n",
      "54/54 [==============================] - 0s 77us/step - loss: 0.3906 - acc: 0.8519\n",
      "Epoch 99/200\n",
      "54/54 [==============================] - 0s 71us/step - loss: 0.3873 - acc: 0.8519\n",
      "Epoch 100/200\n",
      "54/54 [==============================] - 0s 80us/step - loss: 0.3840 - acc: 0.8519\n",
      "Epoch 101/200\n",
      "54/54 [==============================] - 0s 74us/step - loss: 0.3824 - acc: 0.8519\n",
      "Epoch 102/200\n",
      "54/54 [==============================] - 0s 70us/step - loss: 0.3783 - acc: 0.8519\n",
      "Epoch 103/200\n",
      "54/54 [==============================] - 0s 73us/step - loss: 0.3758 - acc: 0.8519\n",
      "Epoch 104/200\n",
      "54/54 [==============================] - 0s 105us/step - loss: 0.3734 - acc: 0.8519\n",
      "Epoch 105/200\n",
      "54/54 [==============================] - 0s 98us/step - loss: 0.3708 - acc: 0.8519\n",
      "Epoch 106/200\n",
      "54/54 [==============================] - 0s 89us/step - loss: 0.3686 - acc: 0.8519\n",
      "Epoch 107/200\n",
      "54/54 [==============================] - 0s 76us/step - loss: 0.3663 - acc: 0.8519\n",
      "Epoch 108/200\n",
      "54/54 [==============================] - 0s 68us/step - loss: 0.3638 - acc: 0.8519\n",
      "Epoch 109/200\n",
      "54/54 [==============================] - 0s 81us/step - loss: 0.3622 - acc: 0.8889\n",
      "Epoch 110/200\n",
      "54/54 [==============================] - 0s 70us/step - loss: 0.3599 - acc: 0.8889\n",
      "Epoch 111/200\n",
      "54/54 [==============================] - 0s 85us/step - loss: 0.3580 - acc: 0.8704\n",
      "Epoch 112/200\n",
      "54/54 [==============================] - 0s 74us/step - loss: 0.3561 - acc: 0.8704\n",
      "Epoch 113/200\n",
      "54/54 [==============================] - 0s 84us/step - loss: 0.3543 - acc: 0.8889\n",
      "Epoch 114/200\n",
      "54/54 [==============================] - 0s 72us/step - loss: 0.3524 - acc: 0.8889\n",
      "Epoch 115/200\n",
      "54/54 [==============================] - 0s 115us/step - loss: 0.3513 - acc: 0.8889\n",
      "Epoch 116/200\n",
      "54/54 [==============================] - 0s 92us/step - loss: 0.3502 - acc: 0.8889\n",
      "Epoch 117/200\n",
      "54/54 [==============================] - 0s 92us/step - loss: 0.3478 - acc: 0.8889\n",
      "Epoch 118/200\n",
      "54/54 [==============================] - 0s 70us/step - loss: 0.3470 - acc: 0.8889\n",
      "Epoch 119/200\n",
      "54/54 [==============================] - 0s 71us/step - loss: 0.3453 - acc: 0.8889\n",
      "Epoch 120/200\n",
      "54/54 [==============================] - 0s 87us/step - loss: 0.3437 - acc: 0.8889\n",
      "Epoch 121/200\n",
      "54/54 [==============================] - 0s 83us/step - loss: 0.3422 - acc: 0.8889\n",
      "Epoch 122/200\n",
      "54/54 [==============================] - 0s 84us/step - loss: 0.3413 - acc: 0.8889\n",
      "Epoch 123/200\n",
      "54/54 [==============================] - 0s 107us/step - loss: 0.3400 - acc: 0.8889\n",
      "Epoch 124/200\n",
      "54/54 [==============================] - 0s 94us/step - loss: 0.3387 - acc: 0.8889\n",
      "Epoch 125/200\n",
      "54/54 [==============================] - 0s 82us/step - loss: 0.3377 - acc: 0.8889\n",
      "Epoch 126/200\n",
      "54/54 [==============================] - 0s 65us/step - loss: 0.3363 - acc: 0.8889\n",
      "Epoch 127/200\n",
      "54/54 [==============================] - 0s 64us/step - loss: 0.3363 - acc: 0.8889\n",
      "Epoch 128/200\n",
      "54/54 [==============================] - 0s 85us/step - loss: 0.3350 - acc: 0.8889\n",
      "Epoch 129/200\n",
      "54/54 [==============================] - 0s 79us/step - loss: 0.3334 - acc: 0.8889\n",
      "Epoch 130/200\n",
      "54/54 [==============================] - 0s 72us/step - loss: 0.3325 - acc: 0.8889\n",
      "Epoch 131/200\n",
      "54/54 [==============================] - 0s 75us/step - loss: 0.3313 - acc: 0.8889\n",
      "Epoch 132/200\n",
      "54/54 [==============================] - 0s 83us/step - loss: 0.3307 - acc: 0.8889\n",
      "Epoch 133/200\n",
      "54/54 [==============================] - 0s 95us/step - loss: 0.3295 - acc: 0.8889\n",
      "Epoch 134/200\n",
      "54/54 [==============================] - 0s 90us/step - loss: 0.3292 - acc: 0.8704\n",
      "Epoch 135/200\n",
      "54/54 [==============================] - 0s 79us/step - loss: 0.3287 - acc: 0.8704\n",
      "Epoch 136/200\n",
      "54/54 [==============================] - 0s 108us/step - loss: 0.3273 - acc: 0.8704\n",
      "Epoch 137/200\n",
      "54/54 [==============================] - 0s 81us/step - loss: 0.3272 - acc: 0.8704\n",
      "Epoch 138/200\n",
      "54/54 [==============================] - 0s 97us/step - loss: 0.3253 - acc: 0.8889\n",
      "Epoch 139/200\n",
      "54/54 [==============================] - 0s 101us/step - loss: 0.3247 - acc: 0.8889\n",
      "Epoch 140/200\n",
      "54/54 [==============================] - 0s 98us/step - loss: 0.3238 - acc: 0.8889\n",
      "Epoch 141/200\n",
      "54/54 [==============================] - 0s 92us/step - loss: 0.3234 - acc: 0.8889\n",
      "Epoch 142/200\n",
      "54/54 [==============================] - 0s 83us/step - loss: 0.3225 - acc: 0.8889\n",
      "Epoch 143/200\n",
      "54/54 [==============================] - 0s 93us/step - loss: 0.3219 - acc: 0.8889\n",
      "Epoch 144/200\n",
      "54/54 [==============================] - 0s 81us/step - loss: 0.3224 - acc: 0.8889\n",
      "Epoch 145/200\n",
      "54/54 [==============================] - 0s 91us/step - loss: 0.3208 - acc: 0.8889\n",
      "Epoch 146/200\n",
      "54/54 [==============================] - 0s 82us/step - loss: 0.3198 - acc: 0.8889\n",
      "Epoch 147/200\n",
      "54/54 [==============================] - 0s 88us/step - loss: 0.3189 - acc: 0.8889\n",
      "Epoch 148/200\n",
      "54/54 [==============================] - 0s 69us/step - loss: 0.3195 - acc: 0.8889\n",
      "Epoch 149/200\n",
      "54/54 [==============================] - 0s 111us/step - loss: 0.3180 - acc: 0.8889\n",
      "Epoch 150/200\n",
      "54/54 [==============================] - 0s 91us/step - loss: 0.3172 - acc: 0.8889\n",
      "Epoch 151/200\n",
      "54/54 [==============================] - 0s 92us/step - loss: 0.3164 - acc: 0.8889\n",
      "Epoch 152/200\n",
      "54/54 [==============================] - 0s 131us/step - loss: 0.3161 - acc: 0.8889\n",
      "Epoch 153/200\n",
      "54/54 [==============================] - 0s 150us/step - loss: 0.3152 - acc: 0.8704\n",
      "Epoch 154/200\n",
      "54/54 [==============================] - 0s 90us/step - loss: 0.3146 - acc: 0.8704\n",
      "Epoch 155/200\n",
      "54/54 [==============================] - 0s 79us/step - loss: 0.3141 - acc: 0.8704\n",
      "Epoch 156/200\n",
      "54/54 [==============================] - 0s 78us/step - loss: 0.3140 - acc: 0.8704\n",
      "Epoch 157/200\n",
      "54/54 [==============================] - 0s 97us/step - loss: 0.3135 - acc: 0.8704\n",
      "Epoch 158/200\n",
      "54/54 [==============================] - 0s 96us/step - loss: 0.3132 - acc: 0.8889\n",
      "Epoch 159/200\n",
      "54/54 [==============================] - 0s 91us/step - loss: 0.3117 - acc: 0.8889\n",
      "Epoch 160/200\n",
      "54/54 [==============================] - 0s 85us/step - loss: 0.3113 - acc: 0.8889\n",
      "Epoch 161/200\n",
      "54/54 [==============================] - 0s 103us/step - loss: 0.3114 - acc: 0.8704\n",
      "Epoch 162/200\n",
      "54/54 [==============================] - 0s 80us/step - loss: 0.3102 - acc: 0.8704\n",
      "Epoch 163/200\n",
      "54/54 [==============================] - 0s 80us/step - loss: 0.3097 - acc: 0.8889\n",
      "Epoch 164/200\n",
      "54/54 [==============================] - 0s 77us/step - loss: 0.3092 - acc: 0.8889\n",
      "Epoch 165/200\n",
      "54/54 [==============================] - 0s 81us/step - loss: 0.3094 - acc: 0.8889\n",
      "Epoch 166/200\n",
      "54/54 [==============================] - 0s 83us/step - loss: 0.3082 - acc: 0.8889\n",
      "Epoch 167/200\n",
      "54/54 [==============================] - 0s 87us/step - loss: 0.3083 - acc: 0.8704\n",
      "Epoch 168/200\n",
      "54/54 [==============================] - 0s 84us/step - loss: 0.3086 - acc: 0.8704\n",
      "Epoch 169/200\n",
      "54/54 [==============================] - 0s 88us/step - loss: 0.3076 - acc: 0.8704\n",
      "Epoch 170/200\n",
      "54/54 [==============================] - 0s 133us/step - loss: 0.3067 - acc: 0.8704\n",
      "Epoch 171/200\n",
      "54/54 [==============================] - 0s 121us/step - loss: 0.3068 - acc: 0.8704\n",
      "Epoch 172/200\n",
      "54/54 [==============================] - 0s 135us/step - loss: 0.3069 - acc: 0.8704\n",
      "Epoch 173/200\n",
      "54/54 [==============================] - 0s 85us/step - loss: 0.3055 - acc: 0.8704\n",
      "Epoch 174/200\n",
      "54/54 [==============================] - 0s 90us/step - loss: 0.3047 - acc: 0.8704\n",
      "Epoch 175/200\n",
      "54/54 [==============================] - 0s 79us/step - loss: 0.3043 - acc: 0.8704\n",
      "Epoch 176/200\n",
      "54/54 [==============================] - 0s 88us/step - loss: 0.3040 - acc: 0.8704\n",
      "Epoch 177/200\n",
      "54/54 [==============================] - 0s 88us/step - loss: 0.3035 - acc: 0.8704\n",
      "Epoch 178/200\n",
      "54/54 [==============================] - 0s 105us/step - loss: 0.3032 - acc: 0.8704\n",
      "Epoch 179/200\n",
      "54/54 [==============================] - 0s 86us/step - loss: 0.3029 - acc: 0.8519\n",
      "Epoch 180/200\n",
      "54/54 [==============================] - 0s 90us/step - loss: 0.3031 - acc: 0.8519\n",
      "Epoch 181/200\n",
      "54/54 [==============================] - 0s 83us/step - loss: 0.3022 - acc: 0.8519\n",
      "Epoch 182/200\n",
      "54/54 [==============================] - 0s 79us/step - loss: 0.3016 - acc: 0.8519\n",
      "Epoch 183/200\n",
      "54/54 [==============================] - 0s 87us/step - loss: 0.3015 - acc: 0.8519\n",
      "Epoch 184/200\n",
      "54/54 [==============================] - 0s 108us/step - loss: 0.3017 - acc: 0.8519\n",
      "Epoch 185/200\n",
      "54/54 [==============================] - 0s 142us/step - loss: 0.3011 - acc: 0.8519\n",
      "Epoch 186/200\n",
      "54/54 [==============================] - 0s 94us/step - loss: 0.3004 - acc: 0.8704\n",
      "Epoch 187/200\n",
      "54/54 [==============================] - 0s 96us/step - loss: 0.3002 - acc: 0.8704\n",
      "Epoch 188/200\n",
      "54/54 [==============================] - 0s 149us/step - loss: 0.2997 - acc: 0.8704\n",
      "Epoch 189/200\n",
      "54/54 [==============================] - 0s 111us/step - loss: 0.3003 - acc: 0.8704\n",
      "Epoch 190/200\n",
      "54/54 [==============================] - 0s 127us/step - loss: 0.2992 - acc: 0.8704\n",
      "Epoch 191/200\n",
      "54/54 [==============================] - 0s 91us/step - loss: 0.3001 - acc: 0.8519\n",
      "Epoch 192/200\n",
      "54/54 [==============================] - 0s 111us/step - loss: 0.2995 - acc: 0.8519\n",
      "Epoch 193/200\n",
      "54/54 [==============================] - 0s 99us/step - loss: 0.2980 - acc: 0.8519\n",
      "Epoch 194/200\n",
      "54/54 [==============================] - 0s 85us/step - loss: 0.2983 - acc: 0.8519\n",
      "Epoch 195/200\n",
      "54/54 [==============================] - 0s 121us/step - loss: 0.2973 - acc: 0.8704\n",
      "Epoch 196/200\n",
      "54/54 [==============================] - 0s 104us/step - loss: 0.2975 - acc: 0.8704\n",
      "Epoch 197/200\n",
      "54/54 [==============================] - 0s 170us/step - loss: 0.2976 - acc: 0.8704\n",
      "Epoch 198/200\n",
      "54/54 [==============================] - 0s 115us/step - loss: 0.2974 - acc: 0.8704\n",
      "Epoch 199/200\n",
      "54/54 [==============================] - 0s 138us/step - loss: 0.2983 - acc: 0.8704\n",
      "Epoch 200/200\n",
      "54/54 [==============================] - 0s 85us/step - loss: 0.2972 - acc: 0.8704\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "Accuracy mean: 0.8509021997451782\n",
      "Accuracy variance: 0.05932192510479003\n"
     ]
    }
   ],
   "source": [
    "# ANN!\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential # initialize neural network library\n",
    "from keras.layers import Dense # build our layers library\n",
    "def build_classifier():\n",
    "    classifier = Sequential() # initialize neural network\n",
    "    classifier.add(Dense(units = 50, kernel_initializer = 'uniform', activation = 'relu', input_dim = x_train.shape[1]))\n",
    "    classifier.add(Dense(units = 10, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier\n",
    "classifier = KerasClassifier(build_fn = build_classifier, epochs = 200)\n",
    "accuracies = cross_val_score(estimator = classifier, X = x_train, y = y_train, cv = 3)\n",
    "mean = accuracies.mean()\n",
    "variance = accuracies.std()\n",
    "print(\"Accuracy mean: \"+ str(mean))\n",
    "print(\"Accuracy variance: \"+ str(variance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_uuid": "b708053280ccbc39ca8dd9f8a52aebb4355c0d19",
    "execution": {
     "iopub.execute_input": "2023-10-25T08:42:08.264948Z",
     "iopub.status.busy": "2023-10-25T08:42:08.264675Z",
     "iopub.status.idle": "2023-10-25T08:42:08.269448Z",
     "shell.execute_reply": "2023-10-25T08:42:08.268582Z",
     "shell.execute_reply.started": "2023-10-25T08:42:08.264899Z"
    }
   },
   "outputs": [],
   "source": [
    "method_names.append(\"ANN\")\n",
    "method_scores.append(0.851)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_uuid": "9a68eec281f6f88ff2548e94935305d9d904b47a",
    "execution": {
     "iopub.execute_input": "2023-10-25T08:42:08.271627Z",
     "iopub.status.busy": "2023-10-25T08:42:08.271285Z",
     "iopub.status.idle": "2023-10-25T08:42:08.286666Z",
     "shell.execute_reply": "2023-10-25T08:42:08.285393Z",
     "shell.execute_reply.started": "2023-10-25T08:42:08.271561Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of trainX is (80, 8, 1)\n",
      "Shape of testX is (20, 8, 1)\n"
     ]
    }
   ],
   "source": [
    "trainX = np.reshape(x_train, (x_train.shape[0], x_train.shape[1],1))\n",
    "testX = np.reshape(x_test, (x_test.shape[0],x_test.shape[1],1))\n",
    "# Print and check shapes\n",
    "print(\"Shape of trainX is {}\".format(trainX.shape))\n",
    "print(\"Shape of testX is {}\".format(testX.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_uuid": "bd120115b813ce73a5667d7dbe3123965e799cf4",
    "execution": {
     "iopub.execute_input": "2023-10-25T08:42:08.290445Z",
     "iopub.status.busy": "2023-10-25T08:42:08.290102Z",
     "iopub.status.idle": "2023-10-25T08:42:21.402843Z",
     "shell.execute_reply": "2023-10-25T08:42:21.401799Z",
     "shell.execute_reply.started": "2023-10-25T08:42:08.290381Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 1.1849 - acc: 0.3125\n",
      "Epoch 2/200\n",
      "80/80 [==============================] - 0s 645us/step - loss: 0.8122 - acc: 0.4375\n",
      "Epoch 3/200\n",
      "80/80 [==============================] - 0s 593us/step - loss: 0.8178 - acc: 0.3750\n",
      "Epoch 4/200\n",
      "80/80 [==============================] - 0s 641us/step - loss: 0.6517 - acc: 0.4250\n",
      "Epoch 5/200\n",
      "80/80 [==============================] - 0s 627us/step - loss: 0.6644 - acc: 0.3750\n",
      "Epoch 6/200\n",
      "80/80 [==============================] - 0s 652us/step - loss: 0.4016 - acc: 0.6375\n",
      "Epoch 7/200\n",
      "80/80 [==============================] - 0s 668us/step - loss: 0.4999 - acc: 0.5250\n",
      "Epoch 8/200\n",
      "80/80 [==============================] - 0s 619us/step - loss: 0.5096 - acc: 0.5125\n",
      "Epoch 9/200\n",
      "80/80 [==============================] - 0s 632us/step - loss: 0.4627 - acc: 0.5375\n",
      "Epoch 10/200\n",
      "80/80 [==============================] - 0s 630us/step - loss: 0.4538 - acc: 0.5750\n",
      "Epoch 11/200\n",
      "80/80 [==============================] - 0s 595us/step - loss: 0.4394 - acc: 0.4625\n",
      "Epoch 12/200\n",
      "80/80 [==============================] - 0s 605us/step - loss: 0.4568 - acc: 0.5250\n",
      "Epoch 13/200\n",
      "80/80 [==============================] - 0s 670us/step - loss: 0.5169 - acc: 0.6250\n",
      "Epoch 14/200\n",
      "80/80 [==============================] - 0s 663us/step - loss: 0.5042 - acc: 0.5375\n",
      "Epoch 15/200\n",
      "80/80 [==============================] - 0s 641us/step - loss: 0.4619 - acc: 0.5375\n",
      "Epoch 16/200\n",
      "80/80 [==============================] - 0s 574us/step - loss: 0.4440 - acc: 0.4875\n",
      "Epoch 17/200\n",
      "80/80 [==============================] - 0s 646us/step - loss: 0.4914 - acc: 0.5000\n",
      "Epoch 18/200\n",
      "80/80 [==============================] - 0s 589us/step - loss: 0.3645 - acc: 0.6625\n",
      "Epoch 19/200\n",
      "80/80 [==============================] - 0s 593us/step - loss: 0.4539 - acc: 0.5500\n",
      "Epoch 20/200\n",
      "80/80 [==============================] - 0s 637us/step - loss: 0.4338 - acc: 0.5375\n",
      "Epoch 21/200\n",
      "80/80 [==============================] - 0s 659us/step - loss: 0.4514 - acc: 0.5875\n",
      "Epoch 22/200\n",
      "80/80 [==============================] - 0s 661us/step - loss: 0.3658 - acc: 0.6625\n",
      "Epoch 23/200\n",
      "80/80 [==============================] - 0s 616us/step - loss: 0.3920 - acc: 0.5625\n",
      "Epoch 24/200\n",
      "80/80 [==============================] - 0s 652us/step - loss: 0.4184 - acc: 0.4875\n",
      "Epoch 25/200\n",
      "80/80 [==============================] - 0s 647us/step - loss: 0.4234 - acc: 0.5500\n",
      "Epoch 26/200\n",
      "80/80 [==============================] - 0s 647us/step - loss: 0.3891 - acc: 0.5375\n",
      "Epoch 27/200\n",
      "80/80 [==============================] - 0s 604us/step - loss: 0.4018 - acc: 0.5000\n",
      "Epoch 28/200\n",
      "80/80 [==============================] - 0s 640us/step - loss: 0.4159 - acc: 0.5500\n",
      "Epoch 29/200\n",
      "80/80 [==============================] - 0s 601us/step - loss: 0.4020 - acc: 0.5625\n",
      "Epoch 30/200\n",
      "80/80 [==============================] - 0s 569us/step - loss: 0.4931 - acc: 0.5000\n",
      "Epoch 31/200\n",
      "80/80 [==============================] - 0s 698us/step - loss: 0.4290 - acc: 0.5750\n",
      "Epoch 32/200\n",
      "80/80 [==============================] - 0s 617us/step - loss: 0.3264 - acc: 0.7000\n",
      "Epoch 33/200\n",
      "80/80 [==============================] - 0s 589us/step - loss: 0.5047 - acc: 0.5500\n",
      "Epoch 34/200\n",
      "80/80 [==============================] - 0s 607us/step - loss: 0.3693 - acc: 0.5875\n",
      "Epoch 35/200\n",
      "80/80 [==============================] - 0s 580us/step - loss: 0.4080 - acc: 0.5250\n",
      "Epoch 36/200\n",
      "80/80 [==============================] - 0s 593us/step - loss: 0.3176 - acc: 0.6500\n",
      "Epoch 37/200\n",
      "80/80 [==============================] - 0s 605us/step - loss: 0.3781 - acc: 0.5750\n",
      "Epoch 38/200\n",
      "80/80 [==============================] - 0s 577us/step - loss: 0.3884 - acc: 0.6000\n",
      "Epoch 39/200\n",
      "80/80 [==============================] - 0s 607us/step - loss: 0.4822 - acc: 0.4875\n",
      "Epoch 40/200\n",
      "80/80 [==============================] - 0s 661us/step - loss: 0.3748 - acc: 0.6000\n",
      "Epoch 41/200\n",
      "80/80 [==============================] - 0s 574us/step - loss: 0.3208 - acc: 0.6000\n",
      "Epoch 42/200\n",
      "80/80 [==============================] - 0s 565us/step - loss: 0.3101 - acc: 0.6125\n",
      "Epoch 43/200\n",
      "80/80 [==============================] - 0s 618us/step - loss: 0.2761 - acc: 0.6875\n",
      "Epoch 44/200\n",
      "80/80 [==============================] - 0s 612us/step - loss: 0.2650 - acc: 0.6875\n",
      "Epoch 45/200\n",
      "80/80 [==============================] - 0s 567us/step - loss: 0.3022 - acc: 0.6375\n",
      "Epoch 46/200\n",
      "80/80 [==============================] - 0s 559us/step - loss: 0.2292 - acc: 0.7250\n",
      "Epoch 47/200\n",
      "80/80 [==============================] - 0s 594us/step - loss: 0.3248 - acc: 0.5750\n",
      "Epoch 48/200\n",
      "80/80 [==============================] - 0s 574us/step - loss: 0.3546 - acc: 0.6000\n",
      "Epoch 49/200\n",
      "80/80 [==============================] - 0s 575us/step - loss: 0.2729 - acc: 0.6500\n",
      "Epoch 50/200\n",
      "80/80 [==============================] - 0s 602us/step - loss: 0.2470 - acc: 0.7250\n",
      "Epoch 51/200\n",
      "80/80 [==============================] - 0s 592us/step - loss: 0.2731 - acc: 0.7000\n",
      "Epoch 52/200\n",
      "80/80 [==============================] - 0s 583us/step - loss: 0.3382 - acc: 0.5875\n",
      "Epoch 53/200\n",
      "80/80 [==============================] - 0s 629us/step - loss: 0.3029 - acc: 0.6625\n",
      "Epoch 54/200\n",
      "80/80 [==============================] - 0s 620us/step - loss: 0.2978 - acc: 0.5625\n",
      "Epoch 55/200\n",
      "80/80 [==============================] - 0s 613us/step - loss: 0.2654 - acc: 0.6625\n",
      "Epoch 56/200\n",
      "80/80 [==============================] - 0s 588us/step - loss: 0.2702 - acc: 0.6250\n",
      "Epoch 57/200\n",
      "80/80 [==============================] - 0s 653us/step - loss: 0.3249 - acc: 0.5500\n",
      "Epoch 58/200\n",
      "80/80 [==============================] - 0s 607us/step - loss: 0.3083 - acc: 0.6375\n",
      "Epoch 59/200\n",
      "80/80 [==============================] - 0s 760us/step - loss: 0.2411 - acc: 0.7000\n",
      "Epoch 60/200\n",
      "80/80 [==============================] - 0s 815us/step - loss: 0.3014 - acc: 0.6625\n",
      "Epoch 61/200\n",
      "80/80 [==============================] - 0s 597us/step - loss: 0.2181 - acc: 0.6625\n",
      "Epoch 62/200\n",
      "80/80 [==============================] - 0s 579us/step - loss: 0.3527 - acc: 0.5125\n",
      "Epoch 63/200\n",
      "80/80 [==============================] - 0s 632us/step - loss: 0.2085 - acc: 0.7125\n",
      "Epoch 64/200\n",
      "80/80 [==============================] - 0s 573us/step - loss: 0.3094 - acc: 0.6375\n",
      "Epoch 65/200\n",
      "80/80 [==============================] - 0s 602us/step - loss: 0.2339 - acc: 0.6750\n",
      "Epoch 66/200\n",
      "80/80 [==============================] - 0s 579us/step - loss: 0.2616 - acc: 0.6500\n",
      "Epoch 67/200\n",
      "80/80 [==============================] - 0s 699us/step - loss: 0.2471 - acc: 0.7250\n",
      "Epoch 68/200\n",
      "80/80 [==============================] - 0s 596us/step - loss: 0.2255 - acc: 0.6750\n",
      "Epoch 69/200\n",
      "80/80 [==============================] - 0s 633us/step - loss: 0.2887 - acc: 0.7500\n",
      "Epoch 70/200\n",
      "80/80 [==============================] - 0s 592us/step - loss: 0.3570 - acc: 0.6625\n",
      "Epoch 71/200\n",
      "80/80 [==============================] - 0s 641us/step - loss: 0.2241 - acc: 0.7625\n",
      "Epoch 72/200\n",
      "80/80 [==============================] - 0s 597us/step - loss: 0.2442 - acc: 0.6125\n",
      "Epoch 73/200\n",
      "80/80 [==============================] - 0s 586us/step - loss: 0.2021 - acc: 0.7125\n",
      "Epoch 74/200\n",
      "80/80 [==============================] - 0s 581us/step - loss: 0.2391 - acc: 0.6750\n",
      "Epoch 75/200\n",
      "80/80 [==============================] - 0s 612us/step - loss: 0.3227 - acc: 0.6250\n",
      "Epoch 76/200\n",
      "80/80 [==============================] - 0s 551us/step - loss: 0.2135 - acc: 0.7125\n",
      "Epoch 77/200\n",
      "80/80 [==============================] - 0s 585us/step - loss: 0.2033 - acc: 0.7125\n",
      "Epoch 78/200\n",
      "80/80 [==============================] - 0s 615us/step - loss: 0.1969 - acc: 0.6875\n",
      "Epoch 79/200\n",
      "80/80 [==============================] - 0s 571us/step - loss: 0.2113 - acc: 0.7000\n",
      "Epoch 80/200\n",
      "80/80 [==============================] - 0s 629us/step - loss: 0.1806 - acc: 0.7875\n",
      "Epoch 81/200\n",
      "80/80 [==============================] - 0s 619us/step - loss: 0.2240 - acc: 0.6875\n",
      "Epoch 82/200\n",
      "80/80 [==============================] - 0s 599us/step - loss: 0.2536 - acc: 0.6625\n",
      "Epoch 83/200\n",
      "80/80 [==============================] - 0s 590us/step - loss: 0.1690 - acc: 0.7750\n",
      "Epoch 84/200\n",
      "80/80 [==============================] - 0s 582us/step - loss: 0.1831 - acc: 0.8000\n",
      "Epoch 85/200\n",
      "80/80 [==============================] - 0s 594us/step - loss: 0.1775 - acc: 0.7625\n",
      "Epoch 86/200\n",
      "80/80 [==============================] - 0s 619us/step - loss: 0.1868 - acc: 0.7375\n",
      "Epoch 87/200\n",
      "80/80 [==============================] - 0s 564us/step - loss: 0.2191 - acc: 0.6875\n",
      "Epoch 88/200\n",
      "80/80 [==============================] - 0s 619us/step - loss: 0.2715 - acc: 0.6500\n",
      "Epoch 89/200\n",
      "80/80 [==============================] - 0s 621us/step - loss: 0.2211 - acc: 0.6500\n",
      "Epoch 90/200\n",
      "80/80 [==============================] - 0s 564us/step - loss: 0.1896 - acc: 0.6750\n",
      "Epoch 91/200\n",
      "80/80 [==============================] - 0s 633us/step - loss: 0.1585 - acc: 0.7750\n",
      "Epoch 92/200\n",
      "80/80 [==============================] - 0s 582us/step - loss: 0.1866 - acc: 0.7250\n",
      "Epoch 93/200\n",
      "80/80 [==============================] - 0s 585us/step - loss: 0.1867 - acc: 0.7625\n",
      "Epoch 94/200\n",
      "80/80 [==============================] - 0s 593us/step - loss: 0.1820 - acc: 0.8000\n",
      "Epoch 95/200\n",
      "80/80 [==============================] - 0s 588us/step - loss: 0.2482 - acc: 0.7375\n",
      "Epoch 96/200\n",
      "80/80 [==============================] - 0s 580us/step - loss: 0.1822 - acc: 0.7625\n",
      "Epoch 97/200\n",
      "80/80 [==============================] - 0s 574us/step - loss: 0.1676 - acc: 0.7500\n",
      "Epoch 98/200\n",
      "80/80 [==============================] - 0s 636us/step - loss: 0.1689 - acc: 0.7750\n",
      "Epoch 99/200\n",
      "80/80 [==============================] - 0s 609us/step - loss: 0.1945 - acc: 0.7250\n",
      "Epoch 100/200\n",
      "80/80 [==============================] - 0s 605us/step - loss: 0.1850 - acc: 0.7375\n",
      "Epoch 101/200\n",
      "80/80 [==============================] - 0s 600us/step - loss: 0.1958 - acc: 0.8000\n",
      "Epoch 102/200\n",
      "80/80 [==============================] - 0s 562us/step - loss: 0.2083 - acc: 0.6750\n",
      "Epoch 103/200\n",
      "80/80 [==============================] - 0s 591us/step - loss: 0.1646 - acc: 0.8000\n",
      "Epoch 104/200\n",
      "80/80 [==============================] - 0s 592us/step - loss: 0.1846 - acc: 0.7250\n",
      "Epoch 105/200\n",
      "80/80 [==============================] - 0s 570us/step - loss: 0.2116 - acc: 0.7000\n",
      "Epoch 106/200\n",
      "80/80 [==============================] - 0s 624us/step - loss: 0.2159 - acc: 0.7375\n",
      "Epoch 107/200\n",
      "80/80 [==============================] - 0s 588us/step - loss: 0.1965 - acc: 0.7750\n",
      "Epoch 108/200\n",
      "80/80 [==============================] - 0s 563us/step - loss: 0.1816 - acc: 0.7500\n",
      "Epoch 109/200\n",
      "80/80 [==============================] - 0s 585us/step - loss: 0.1567 - acc: 0.8125\n",
      "Epoch 110/200\n",
      "80/80 [==============================] - 0s 584us/step - loss: 0.2233 - acc: 0.7000\n",
      "Epoch 111/200\n",
      "80/80 [==============================] - 0s 648us/step - loss: 0.1830 - acc: 0.7625\n",
      "Epoch 112/200\n",
      "80/80 [==============================] - 0s 633us/step - loss: 0.2105 - acc: 0.7000\n",
      "Epoch 113/200\n",
      "80/80 [==============================] - 0s 577us/step - loss: 0.1696 - acc: 0.7500\n",
      "Epoch 114/200\n",
      "80/80 [==============================] - 0s 559us/step - loss: 0.1821 - acc: 0.7125\n",
      "Epoch 115/200\n",
      "80/80 [==============================] - 0s 631us/step - loss: 0.1791 - acc: 0.7250\n",
      "Epoch 116/200\n",
      "80/80 [==============================] - 0s 559us/step - loss: 0.1800 - acc: 0.7625\n",
      "Epoch 117/200\n",
      "80/80 [==============================] - 0s 699us/step - loss: 0.1400 - acc: 0.8125\n",
      "Epoch 118/200\n",
      "80/80 [==============================] - 0s 604us/step - loss: 0.1574 - acc: 0.8000\n",
      "Epoch 119/200\n",
      "80/80 [==============================] - 0s 566us/step - loss: 0.1644 - acc: 0.7625\n",
      "Epoch 120/200\n",
      "80/80 [==============================] - 0s 658us/step - loss: 0.1935 - acc: 0.7250\n",
      "Epoch 121/200\n",
      "80/80 [==============================] - 0s 588us/step - loss: 0.1703 - acc: 0.8125\n",
      "Epoch 122/200\n",
      "80/80 [==============================] - 0s 615us/step - loss: 0.2057 - acc: 0.6875\n",
      "Epoch 123/200\n",
      "80/80 [==============================] - 0s 655us/step - loss: 0.1231 - acc: 0.8125\n",
      "Epoch 124/200\n",
      "80/80 [==============================] - 0s 604us/step - loss: 0.1819 - acc: 0.7875\n",
      "Epoch 125/200\n",
      "80/80 [==============================] - 0s 631us/step - loss: 0.1711 - acc: 0.7625\n",
      "Epoch 126/200\n",
      "80/80 [==============================] - 0s 622us/step - loss: 0.1498 - acc: 0.8000\n",
      "Epoch 127/200\n",
      "80/80 [==============================] - 0s 572us/step - loss: 0.1650 - acc: 0.7875\n",
      "Epoch 128/200\n",
      "80/80 [==============================] - 0s 588us/step - loss: 0.1303 - acc: 0.8250\n",
      "Epoch 129/200\n",
      "80/80 [==============================] - 0s 599us/step - loss: 0.1582 - acc: 0.8500\n",
      "Epoch 130/200\n",
      "80/80 [==============================] - 0s 574us/step - loss: 0.1601 - acc: 0.7500\n",
      "Epoch 131/200\n",
      "80/80 [==============================] - 0s 590us/step - loss: 0.1406 - acc: 0.8375\n",
      "Epoch 132/200\n",
      "80/80 [==============================] - 0s 621us/step - loss: 0.1362 - acc: 0.8000\n",
      "Epoch 133/200\n",
      "80/80 [==============================] - 0s 620us/step - loss: 0.1689 - acc: 0.7750\n",
      "Epoch 134/200\n",
      "80/80 [==============================] - 0s 600us/step - loss: 0.1380 - acc: 0.8000\n",
      "Epoch 135/200\n",
      "80/80 [==============================] - 0s 611us/step - loss: 0.1721 - acc: 0.7375\n",
      "Epoch 136/200\n",
      "80/80 [==============================] - 0s 585us/step - loss: 0.1720 - acc: 0.8125\n",
      "Epoch 137/200\n",
      "80/80 [==============================] - 0s 606us/step - loss: 0.1206 - acc: 0.8375\n",
      "Epoch 138/200\n",
      "80/80 [==============================] - 0s 564us/step - loss: 0.1547 - acc: 0.8125\n",
      "Epoch 139/200\n",
      "80/80 [==============================] - 0s 600us/step - loss: 0.1435 - acc: 0.8625\n",
      "Epoch 140/200\n",
      "80/80 [==============================] - 0s 627us/step - loss: 0.1737 - acc: 0.7750\n",
      "Epoch 141/200\n",
      "80/80 [==============================] - 0s 543us/step - loss: 0.1309 - acc: 0.8375\n",
      "Epoch 142/200\n",
      "80/80 [==============================] - 0s 595us/step - loss: 0.1665 - acc: 0.8250\n",
      "Epoch 143/200\n",
      "80/80 [==============================] - 0s 575us/step - loss: 0.1911 - acc: 0.7500\n",
      "Epoch 144/200\n",
      "80/80 [==============================] - 0s 669us/step - loss: 0.1364 - acc: 0.7750\n",
      "Epoch 145/200\n",
      "80/80 [==============================] - 0s 613us/step - loss: 0.1695 - acc: 0.7875\n",
      "Epoch 146/200\n",
      "80/80 [==============================] - 0s 575us/step - loss: 0.1629 - acc: 0.7875\n",
      "Epoch 147/200\n",
      "80/80 [==============================] - 0s 646us/step - loss: 0.1106 - acc: 0.8875\n",
      "Epoch 148/200\n",
      "80/80 [==============================] - 0s 573us/step - loss: 0.1772 - acc: 0.7625\n",
      "Epoch 149/200\n",
      "80/80 [==============================] - 0s 650us/step - loss: 0.1448 - acc: 0.7750\n",
      "Epoch 150/200\n",
      "80/80 [==============================] - 0s 566us/step - loss: 0.1299 - acc: 0.8500\n",
      "Epoch 151/200\n",
      "80/80 [==============================] - 0s 607us/step - loss: 0.1486 - acc: 0.8000\n",
      "Epoch 152/200\n",
      "80/80 [==============================] - 0s 654us/step - loss: 0.1432 - acc: 0.8750\n",
      "Epoch 153/200\n",
      "80/80 [==============================] - 0s 582us/step - loss: 0.1747 - acc: 0.7500\n",
      "Epoch 154/200\n",
      "80/80 [==============================] - 0s 654us/step - loss: 0.1427 - acc: 0.8375\n",
      "Epoch 155/200\n",
      "80/80 [==============================] - 0s 593us/step - loss: 0.1668 - acc: 0.7625\n",
      "Epoch 156/200\n",
      "80/80 [==============================] - 0s 573us/step - loss: 0.1606 - acc: 0.7875\n",
      "Epoch 157/200\n",
      "80/80 [==============================] - 0s 623us/step - loss: 0.1613 - acc: 0.8000\n",
      "Epoch 158/200\n",
      "80/80 [==============================] - 0s 575us/step - loss: 0.1196 - acc: 0.8125\n",
      "Epoch 159/200\n",
      "80/80 [==============================] - 0s 617us/step - loss: 0.1526 - acc: 0.8000\n",
      "Epoch 160/200\n",
      "80/80 [==============================] - 0s 590us/step - loss: 0.1503 - acc: 0.8000\n",
      "Epoch 161/200\n",
      "80/80 [==============================] - 0s 598us/step - loss: 0.1351 - acc: 0.8500\n",
      "Epoch 162/200\n",
      "80/80 [==============================] - 0s 594us/step - loss: 0.1625 - acc: 0.7750\n",
      "Epoch 163/200\n",
      "80/80 [==============================] - 0s 560us/step - loss: 0.1688 - acc: 0.7625\n",
      "Epoch 164/200\n",
      "80/80 [==============================] - 0s 575us/step - loss: 0.1148 - acc: 0.8375\n",
      "Epoch 165/200\n",
      "80/80 [==============================] - 0s 586us/step - loss: 0.1242 - acc: 0.8250\n",
      "Epoch 166/200\n",
      "80/80 [==============================] - 0s 607us/step - loss: 0.1452 - acc: 0.8500\n",
      "Epoch 167/200\n",
      "80/80 [==============================] - 0s 629us/step - loss: 0.1258 - acc: 0.8625\n",
      "Epoch 168/200\n",
      "80/80 [==============================] - 0s 583us/step - loss: 0.1366 - acc: 0.8375\n",
      "Epoch 169/200\n",
      "80/80 [==============================] - 0s 605us/step - loss: 0.1306 - acc: 0.8250\n",
      "Epoch 170/200\n",
      "80/80 [==============================] - 0s 620us/step - loss: 0.1227 - acc: 0.8750\n",
      "Epoch 171/200\n",
      "80/80 [==============================] - 0s 579us/step - loss: 0.1489 - acc: 0.8000\n",
      "Epoch 172/200\n",
      "80/80 [==============================] - 0s 579us/step - loss: 0.1630 - acc: 0.8125\n",
      "Epoch 173/200\n",
      "80/80 [==============================] - 0s 614us/step - loss: 0.1509 - acc: 0.8375\n",
      "Epoch 174/200\n",
      "80/80 [==============================] - 0s 549us/step - loss: 0.1436 - acc: 0.8375\n",
      "Epoch 175/200\n",
      "80/80 [==============================] - 0s 603us/step - loss: 0.1447 - acc: 0.8125\n",
      "Epoch 176/200\n",
      "80/80 [==============================] - 0s 578us/step - loss: 0.1349 - acc: 0.8125\n",
      "Epoch 177/200\n",
      "80/80 [==============================] - 0s 607us/step - loss: 0.1280 - acc: 0.8250\n",
      "Epoch 178/200\n",
      "80/80 [==============================] - 0s 644us/step - loss: 0.1498 - acc: 0.8000\n",
      "Epoch 179/200\n",
      "80/80 [==============================] - 0s 576us/step - loss: 0.1310 - acc: 0.8500\n",
      "Epoch 180/200\n",
      "80/80 [==============================] - 0s 607us/step - loss: 0.1323 - acc: 0.8375\n",
      "Epoch 181/200\n",
      "80/80 [==============================] - 0s 586us/step - loss: 0.1228 - acc: 0.8875\n",
      "Epoch 182/200\n",
      "80/80 [==============================] - 0s 570us/step - loss: 0.1173 - acc: 0.8500\n",
      "Epoch 183/200\n",
      "80/80 [==============================] - 0s 601us/step - loss: 0.1228 - acc: 0.8625\n",
      "Epoch 184/200\n",
      "80/80 [==============================] - 0s 582us/step - loss: 0.1490 - acc: 0.7875\n",
      "Epoch 185/200\n",
      "80/80 [==============================] - 0s 609us/step - loss: 0.1441 - acc: 0.8500\n",
      "Epoch 186/200\n",
      "80/80 [==============================] - 0s 623us/step - loss: 0.1255 - acc: 0.8125\n",
      "Epoch 187/200\n",
      "80/80 [==============================] - 0s 655us/step - loss: 0.1188 - acc: 0.8500\n",
      "Epoch 188/200\n",
      "80/80 [==============================] - 0s 560us/step - loss: 0.1418 - acc: 0.8500\n",
      "Epoch 189/200\n",
      "80/80 [==============================] - 0s 585us/step - loss: 0.1246 - acc: 0.8500\n",
      "Epoch 190/200\n",
      "80/80 [==============================] - 0s 611us/step - loss: 0.1433 - acc: 0.8250\n",
      "Epoch 191/200\n",
      "80/80 [==============================] - 0s 617us/step - loss: 0.1227 - acc: 0.8500\n",
      "Epoch 192/200\n",
      "80/80 [==============================] - 0s 570us/step - loss: 0.0936 - acc: 0.9125\n",
      "Epoch 193/200\n",
      "80/80 [==============================] - 0s 619us/step - loss: 0.1191 - acc: 0.8875\n",
      "Epoch 194/200\n",
      "80/80 [==============================] - 0s 609us/step - loss: 0.1030 - acc: 0.8625\n",
      "Epoch 195/200\n",
      "80/80 [==============================] - 0s 630us/step - loss: 0.0889 - acc: 0.9250\n",
      "Epoch 196/200\n",
      "80/80 [==============================] - 0s 620us/step - loss: 0.1373 - acc: 0.8125\n",
      "Epoch 197/200\n",
      "80/80 [==============================] - 0s 677us/step - loss: 0.1164 - acc: 0.8875\n",
      "Epoch 198/200\n",
      "80/80 [==============================] - 0s 585us/step - loss: 0.1320 - acc: 0.8750\n",
      "Epoch 199/200\n",
      "80/80 [==============================] - 0s 621us/step - loss: 0.1250 - acc: 0.8250\n",
      "Epoch 200/200\n",
      "80/80 [==============================] - 0s 632us/step - loss: 0.1104 - acc: 0.8750\n",
      "Accuracy mean: 0.8509021997451782\n",
      "Accuracy variance: 0.05932192510479003\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, SimpleRNN, Dropout\n",
    "from keras.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "model = Sequential()\n",
    "# Add the first layer and Dropout regularization\n",
    "model.add(SimpleRNN(units=100,activation='tanh',return_sequences=True, \n",
    "                    input_shape=(trainX.shape[1],1)))\n",
    "model.add(Dropout(0.20))\n",
    "# Second layer and Dropout regularization\n",
    "model.add(SimpleRNN(units = 100, activation='tanh',return_sequences=True))\n",
    "model.add(Dropout(0.20))\n",
    "# Third layer and Dropout regularization\n",
    "model.add(SimpleRNN(units = 70, activation='tanh', return_sequences= True))\n",
    "model.add(Dropout(0.20))\n",
    "# Fourth layer and Dropout regularization\n",
    "model.add(SimpleRNN(units = 50))\n",
    "model.add(Dropout(0.20))\n",
    "# Add final or output layer\n",
    "model.add(Dense(units=1))\n",
    "\n",
    "# Compile our RNN model\n",
    "model.compile(optimizer = 'adam', loss = 'mean_squared_error',metrics = ['accuracy'])\n",
    "# Fitting the RNN to the training set\n",
    "model.fit(trainX, y_train, epochs = 200, batch_size=32)\n",
    "# Remember; epochs, batch_size etc. are just some of hyper parameters. \n",
    "# You can change these parameters whatever you want\n",
    "mean = accuracies.mean()\n",
    "variance = accuracies.std()\n",
    "print(\"Accuracy mean: \"+ str(mean))\n",
    "print(\"Accuracy variance: \"+ str(variance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_uuid": "6b90913a8a1a728d6f6d500ac683417af7b6a370",
    "execution": {
     "iopub.execute_input": "2023-10-25T08:42:21.407730Z",
     "iopub.status.busy": "2023-10-25T08:42:21.406159Z",
     "iopub.status.idle": "2023-10-25T08:42:21.412087Z",
     "shell.execute_reply": "2023-10-25T08:42:21.411416Z",
     "shell.execute_reply.started": "2023-10-25T08:42:21.407671Z"
    }
   },
   "outputs": [],
   "source": [
    "method_names.append(\"RNN\")\n",
    "method_scores.append(0.887)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "89fae4f677c7d6638e95f040fea61aae7e3493f8"
   },
   "source": [
    "**CONCLUSION**\n",
    "\n",
    "We've already completed to train our data with a lot of different method. Let's look which method is given the best result to us!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_uuid": "af35e768076f7018e68d2d191ffb12e64d7fef06",
    "execution": {
     "iopub.execute_input": "2023-10-25T08:42:21.414219Z",
     "iopub.status.busy": "2023-10-25T08:42:21.413562Z",
     "iopub.status.idle": "2023-10-25T08:42:21.902550Z",
     "shell.execute_reply": "2023-10-25T08:42:21.901633Z",
     "shell.execute_reply.started": "2023-10-25T08:42:21.414156Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Method Score')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plt.ylim([0.60,0.90])\n",
    "plt.bar(method_names,method_scores,width=0.5)\n",
    "plt.xlabel('Method Name')\n",
    "plt.ylabel('Method Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c7174b5604b31c95b8d6fc16205719b3cce83e02"
   },
   "source": [
    "As we can see easily; RNN gave us the best result! I hope you learned something like I did. Please comment me!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "_uuid": "0ded5dd1b51582fdb1027bd24ca3ca6fb74c0b45"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
